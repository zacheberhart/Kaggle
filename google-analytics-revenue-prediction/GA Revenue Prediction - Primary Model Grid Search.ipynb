{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/floyd/home\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import os.path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from pandas.io.json import json_normalize\n",
    "from random import randint\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "from time import sleep\n",
    "\n",
    "from fastai.structured import *\n",
    "from fastai.column_data import *\n",
    "np.set_printoptions(threshold=50, edgeitems=20)\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# set path\n",
    "PATH = '../input/'\n",
    "! pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture Grid Search\n",
    "\n",
    "*(final conclusions about the competition results at the end of the notebook)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(csv_path, nrows = None):\n",
    "    \n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    \n",
    "    df = pd.read_csv(csv_path, \n",
    "                     converters={column: json.loads for column in JSON_COLUMNS}, \n",
    "                     dtype={'fullVisitorId': 'str'}, # Important!!\n",
    "                     nrows=nrows)\n",
    "    \n",
    "    for column in JSON_COLUMNS:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    \n",
    "    df['date'] = df['date'].apply(lambda x: datetime.date(int(str(x)[:4]), int(str(x)[4:6]), int(str(x)[6:])))\n",
    "    df['date'] = pd.to_datetime(df['date'], format = '%Y-%m-%d')\n",
    "    df = df.drop([c for c in df.columns if df[c].nunique() == 1], 1).copy()\n",
    "    df['visitStartTime'] = pd.to_datetime(df['visitStartTime'], unit = 's')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_all_locations_in_data(df):\n",
    "\n",
    "    city_country = df[['geoNetwork.city', 'geoNetwork.country']]\n",
    "    city_country = city_country[(city_country['geoNetwork.city'] != 'not available in demo dataset') &\n",
    "                                (city_country['geoNetwork.city'] != '(not set)') &\n",
    "                                (city_country['geoNetwork.country'] != '(not set)')\n",
    "                               ].copy()\n",
    "    city_country = city_country.drop_duplicates().reset_index(drop = True)\n",
    "    city_country.columns = ['city', 'country']\n",
    "    city_country['city_country'] = city_country['city'] + ', ' + city_country['country']\n",
    "\n",
    "    location_list = city_country.city_country.tolist()\n",
    "    \n",
    "    return location_list\n",
    "\n",
    "def get_tz_by_city(location_list):\n",
    "    \n",
    "    # use Google Maps Geocoding API\n",
    "    g = geocoders.GoogleV3(api_key = 'AIzaSyDTzsmQA9PypUvh0M-IHrR5zatvn9n0Li4')\n",
    "    tz = tzwhere.tzwhere()\n",
    "    tzs_list = []\n",
    "    \n",
    "    # loop through each location and search for TZ\n",
    "    for location in location_list:\n",
    "        try:\n",
    "            print(location)\n",
    "            place, (lat, lng) = g.geocode(location)\n",
    "            tz_str = tz.tzNameAt(lat, lng)\n",
    "            print(tz_str, '\\n')\n",
    "            tzs_list.append({'city': location, 'tz': tz_str})\n",
    "        except:\n",
    "            tzs_list.append({'city': 'error', 'tz': 'error'})\n",
    "        \n",
    "        # paced calls to reduce errors\n",
    "        sleep(0.25)\n",
    "    \n",
    "    return pd.DataFrame(tzs_list)\n",
    "\n",
    "def convert_dtypes_fastai_nn(train, test, dep_label, dt_label, convert_cat = True, convert_contin = True):\n",
    "    \n",
    "    # set cols for train and test\n",
    "    print('setting cols in train and test')\n",
    "    train = train[cat_vars + contin_vars + [dep_label, dt_label]].copy()\n",
    "    test[dep_label] = 0\n",
    "    test = test[cat_vars + contin_vars + [dep_label, dt_label]].copy()\n",
    "    \n",
    "    # convert categorical features\n",
    "    if convert_cat:\n",
    "        print('converting categorial features')\n",
    "        for v in cat_vars:\n",
    "            train[v] = train[v].astype('category').cat.as_ordered()\n",
    "        apply_cats(test, train)\n",
    "    \n",
    "    # convert continuous features\n",
    "    if convert_contin:\n",
    "        print('converting continuous features')\n",
    "        for v in contin_vars:\n",
    "            train[v] = train[v].fillna(0).astype('float32')\n",
    "            test[v] = test[v].fillna(0).astype('float32')\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "def get_training_sample(use_sample, df, sample_size, dt_label):\n",
    "    \n",
    "    if use_sample:\n",
    "        n = len(df)\n",
    "        df = df.iloc[get_cv_idxs(n, val_pct = sample_size / n)].copy()\n",
    "    \n",
    "    samp = df.set_index(dt_label)\n",
    "    print('training shape:', samp.shape)\n",
    "    \n",
    "    return samp\n",
    "\n",
    "def get_timeseries_val_idxs(df, val_type, val_pct = 0.2, val_days = 21):\n",
    "    \n",
    "    n = len(df)\n",
    "    \n",
    "    if val_type == 'pct':\n",
    "        val_idx = get_cv_idxs(n, val_pct = val_pct)\n",
    "    \n",
    "    elif val_type == 'days':\n",
    "        qd = pd.DataFrame({'days': [d.split()[0] for d in df.index.sort_values().astype(str).tolist()]}\n",
    "                         ).drop_duplicates().sort_values('days').reset_index(drop = True)\n",
    "        val_start = pd.to_datetime(qd[-val_days:].reset_index(drop = True).iloc[0].days)\n",
    "        val_idx = np.flatnonzero(df.index >= val_start)\n",
    "    \n",
    "    print('Validation Size:', len(val_idx) / n)\n",
    "    \n",
    "    return val_idx\n",
    "\n",
    "def _rmse(y_pred, targ):\n",
    "    var = targ - y_pred\n",
    "    return math.sqrt((var ** 2).mean())\n",
    "\n",
    "def neg_rmse(y_pred, targ):\n",
    "    return _rmse(y_pred, targ) * (-1)\n",
    "\n",
    "def print_embedding_complexity(emb_szs):\n",
    "    _sum = 0\n",
    "    for e in emb_szs:\n",
    "        f, ee = e\n",
    "        _sum += (f * ee)\n",
    "    print('Embedding Complexity:', _sum)\n",
    "\n",
    "def get_all_data_objects(fname):\n",
    "    \n",
    "    # set pickel path\n",
    "    data_path = PATH+fname; data_path\n",
    "    \n",
    "    # read in pickel\n",
    "    n_bytes = 2**31\n",
    "    max_bytes = int((2**31) * 0.999)\n",
    "    data = bytearray(n_bytes)\n",
    "    bytes_in = bytearray(0)\n",
    "    input_size = os.path.getsize(data_path)\n",
    "    print('Total Data Size:', input_size)\n",
    "    with open(data_path, 'rb') as f_in:\n",
    "        for _ in range(0, input_size, max_bytes):\n",
    "            print(_)\n",
    "            bytes_in += f_in.read(max_bytes)\n",
    "    data = pickle.loads(bytes_in)\n",
    "    \n",
    "    # df, df_test, y, nas, mapper, cat_sz, emb_szs\n",
    "    return deepcopy(data['df']), deepcopy(data['df_test']), deepcopy(data['y']), deepcopy(data['feat_imp']), deepcopy(data['nas']), deepcopy(data['mapper']), deepcopy(data['cat_sz']), deepcopy(data['emb_szs'])\n",
    "\n",
    "def get_features(n_features):\n",
    "    \n",
    "    if n_features < len(base_features):\n",
    "        print('number of features must be greater than', len(base_features))\n",
    "        return None\n",
    "    \n",
    "    feature_set = list(set(base_features + feat_imp[:n_features - len(base_features)]))\n",
    "    dups = 0\n",
    "    \n",
    "    while len(feature_set) < n_features:\n",
    "        dups += 1\n",
    "        feature_set = list(set(base_features + feat_imp[:dups + n_features - len(base_features)]))\n",
    "    \n",
    "    return feature_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit w/ Full Feature Engineered Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = 'kaggle_ga_revenue_mainpoly_processed_data_pkl/main&poly_processed_data_objects.pkl'\n",
    "# df, df_test, y, feat_imp, nas, mapper, cat_sz, emb_szs = get_all_data_objects(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = [\n",
    "    \n",
    "    'channelGrouping', 'device.browser', 'device.deviceCategory',\n",
    "    'device.isMobile', 'device.operatingSystem', 'geoNetwork.city', 'geoNetwork.continent',\n",
    "    'geoNetwork.country', 'geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region',\n",
    "    'geoNetwork.subContinent', 'trafficSource.adContent', 'trafficSource.adwordsClickInfo.adNetworkType',\n",
    "    'trafficSource.adwordsClickInfo.gclId', 'trafficSource.adwordsClickInfo.page', 'trafficSource.adwordsClickInfo.slot',\n",
    "    'trafficSource.campaign', 'trafficSource.keyword', 'trafficSource.medium', 'trafficSource.referralPath',\n",
    "    'trafficSource.source', 'visitStartTimeLOCALYear', 'visitStartTimeLOCALMonth', 'visitStartTimeLOCALWeek',\n",
    "    'visitStartTimeLOCALDay', 'visitStartTimeLOCALDayofweek', 'visitStartTimeLOCALDayofyear', 'visitStartTimeLOCALIs_month_end',\n",
    "    'visitStartTimeLOCALIs_month_start', 'visitStartTimeLOCALIs_quarter_end', 'visitStartTimeLOCALIs_quarter_start',\n",
    "    'visitStartTimeLOCALIs_year_end', 'visitStartTimeLOCALIs_year_start', 'visitStartTimeLOCALHourofday',\n",
    "    'return_visit', 'landing', 'bounce', 'user_has_purchased_before', 'browser_os', 'browser_device', 'os_device',\n",
    "    'channel_device', 'channel_domain', 'city_country_mismatch', 'is_holiday'\n",
    "    \n",
    "]\n",
    "\n",
    "contin_vars = [\n",
    "    \n",
    "    'totals.hits', 'totals.pageviews', 'visitNumber', 'days_after_holiday', 'days_before_holiday',\n",
    "    'holiday_anticipation', 'holiday_gap', 'days_since_last_visit', 'days_since_first_visit'\n",
    "    \n",
    "]\n",
    "\n",
    "hold_cols = [\n",
    "    \n",
    "    'dataset', 'date', 'fullVisitorId', 'sessionId', 'totals.transactionRevenue', 'visitId',\n",
    "    'visitStartTime', 'visitStartTimeLOCAL', 'visitStartTimeLOCALElapsed'\n",
    "\n",
    "]\n",
    "\n",
    "# always keep these features in dataset despite importance filtering\n",
    "base_features = deepcopy(cat_vars + contin_vars)\n",
    "\n",
    "# set remaining cols as continuous\n",
    "additional_contin_vars = deepcopy([c for c in df.columns if c not in cat_vars + contin_vars + hold_cols])\n",
    "\n",
    "# add the additional engineered cols to continuous\n",
    "contin_vars += additional_contin_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model build / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_pct = 0.40\n",
    "dep = 'totals.transactionRevenue'\n",
    "dt = 'visitStartTimeLOCAL'\n",
    "\n",
    "# set target\n",
    "yl = np.log1p(y)\n",
    "y_range = (0, np.max(yl) * 1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Validation Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set validation\n",
    "# val_idx = pd.Series(get_timeseries_val_idxs(df,\n",
    "#                                             val_type = 'pct',\n",
    "#                                             val_pct = validation_pct)\n",
    "#                    ).sort_values().values.reshape(-1,)\n",
    "\n",
    "# # pickel validation for later model compare\n",
    "# dt_str = datetime.datetime.utcnow().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "# with open('val_idx_saves/validation_idxs_{}.pkl'.format(dt_str), 'wb') as output:\n",
    "#     pickle.dump(val_idx, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1Cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search - Weight Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx_filename = 'val_idx_saves/validation_idxs_2018-10-11-13-08-53.pkl'\n",
    "\n",
    "with open(val_idx_filename, \"rb\") as input_file:\n",
    "    val_idx = pickle.load(input_file)\n",
    "\n",
    "dt_str = val_idx_filename.split('_')[-1].split('.')[0]\n",
    "\n",
    "arch = [4096, 2048]\n",
    "dropouts = [\n",
    "    #[0.01, 0.01],\n",
    "    [0.1, 0.1],\n",
    "    [0.2, 0.2],\n",
    "    [0.3, 0.3]\n",
    "]\n",
    "wds = [1e-3, 1e-4, 1e-5, 1e-6, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wd_grid_search_iter(wd, dropout):\n",
    "        \n",
    "        model_name = 'full_features_1cycle_NE_wdgs_wd{}_dropout{}_{}'.format(wd, dropout[0], dt_str)\n",
    "        print('\\n\\nStarting:', model_name)\n",
    "        \n",
    "        # init model\n",
    "        md = ColumnarModelData.from_data_frame(path = 'models', val_idxs = val_idx, df = df, y = yl.astype(np.float32),\n",
    "                                               cat_flds = cat_vars, bs = 128, test_df = df_test)\n",
    "        m = md.get_learner(emb_szs = emb_szs, n_cont = len(df.columns) - len(cat_vars),\n",
    "                           emb_drop = 0.04, out_sz = 1, szs = arch, drops = dropout, y_range = y_range)\n",
    "\n",
    "        # fit model\n",
    "        m.fit(lrs = 1e-4, n_cycle = 1, cycle_len = 16,\n",
    "              wds = wd, use_wd_sched = True, use_clr_beta = (10, 10, 0.95, 0.85),\n",
    "              metrics = [neg_rmse], best_save_name = model_name)\n",
    "        \n",
    "        del md, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dropout in dropouts:\n",
    "    for wd in wds:\n",
    "        wd_grid_search_iter(wd = wd, dropout = dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models & Compare Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_get_val_loss(saved_weights, loc_val_idx):\n",
    "    \n",
    "    # get data object\n",
    "    md = ColumnarModelData.from_data_frame(path = 'models', val_idxs = loc_val_idx, df = df,\n",
    "                                           y = yl.astype(np.float32), cat_flds = cat_vars,\n",
    "                                           bs = 128, test_df = df_test)\n",
    "    \n",
    "    # init model\n",
    "    dropout = [float(saved_weights.split('_')[-2].replace('dropout', '')) for _ in range(2)]\n",
    "    m = md.get_learner(emb_szs = emb_szs, n_cont = len(df.columns) - len(cat_vars),\n",
    "                       emb_drop = 0.04, out_sz = 1, szs = arch, drops = dropout, y_range = y_range)\n",
    "    \n",
    "    # load saved weights\n",
    "    m.load(saved_weights)\n",
    "    \n",
    "    # calc rmse\n",
    "    yl_val = deepcopy(yl[loc_val_idx])\n",
    "    yl_hat = deepcopy(m.predict().reshape(-1,))\n",
    "    loss = deepcopy(neg_rmse(yl_hat, yl_val))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = [4096, 2048]\n",
    "val_idx_filename = 'val_idx_saves/validation_idxs_2018-10-11-13-08-53.pkl'\n",
    "\n",
    "with open('saved_weights_backup.pkl', \"rb\") as f:\n",
    "    saved_weights = pickle.load(f)\n",
    "\n",
    "with open(val_idx_filename, \"rb\") as f:\n",
    "    testing_val_idx = pickle.load(f)\n",
    "\n",
    "testing_val_idx = deepcopy(pd.DataFrame(\n",
    "    {'val_idxs': testing_val_idx}\n",
    ").sort_values('val_idxs').values.reshape(-1,))\n",
    "\n",
    "overall_loss = {}\n",
    "for w in saved_weights:\n",
    "    print('starting:', w)\n",
    "    overall_loss[w] = load_model_get_val_loss(w, testing_val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performace = pd.DataFrame([deepcopy({'model': k, 'loss': v}) for k, v in overall_loss.items()])\n",
    "model_performace['weight_decay'] = model_performace['model'].apply(lambda x: x.split('_')[-3].replace('wd',''))\n",
    "model_performace['dropout'] = model_performace['model'].apply(lambda x: x.split('_')[-2].replace('dropout',''))\n",
    "model_performace['loss'] = deepcopy(abs(model_performace['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>model</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.578437</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd0.0001_dropout0...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.581001</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd1e-05_dropout0....</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.585259</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd0_dropout0.2_20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.586565</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd0.001_dropout0....</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.590284</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd1e-06_dropout0....</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.590392</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd0.0001_dropout0...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.591376</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd0.001_dropout0....</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.592070</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd0.0001_dropout0...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.592244</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd0_dropout0.3_20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.593640</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd0.001_dropout0....</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.595447</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd0_dropout0.01_2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.596082</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd1e-06_dropout0....</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.596191</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd1e-06_dropout0....</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.596990</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd1e-05_dropout0....</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.597008</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd0_dropout0.1_20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.597551</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd1e-05_dropout0....</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.599455</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd1e-05_dropout0....</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.602023</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd0.0001_dropout0...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.607627</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd0.001_dropout0....</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.616526</td>\n",
       "      <td>full_features_1cycle_NE_wdgs_wd1e-06_dropout0....</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss                                              model weight_decay  \\\n",
       "9   1.578437  full_features_1cycle_NE_wdgs_wd0.0001_dropout0...       0.0001   \n",
       "16  1.581001  full_features_1cycle_NE_wdgs_wd1e-05_dropout0....        1e-05   \n",
       "6   1.585259  full_features_1cycle_NE_wdgs_wd0_dropout0.2_20...            0   \n",
       "13  1.586565  full_features_1cycle_NE_wdgs_wd0.001_dropout0....        0.001   \n",
       "19  1.590284  full_features_1cycle_NE_wdgs_wd1e-06_dropout0....        1e-06   \n",
       "10  1.590392  full_features_1cycle_NE_wdgs_wd0.0001_dropout0...       0.0001   \n",
       "4   1.591376  full_features_1cycle_NE_wdgs_wd0.001_dropout0....        0.001   \n",
       "3   1.592070  full_features_1cycle_NE_wdgs_wd0.0001_dropout0...       0.0001   \n",
       "7   1.592244  full_features_1cycle_NE_wdgs_wd0_dropout0.3_20...            0   \n",
       "12  1.593640  full_features_1cycle_NE_wdgs_wd0.001_dropout0....        0.001   \n",
       "0   1.595447  full_features_1cycle_NE_wdgs_wd0_dropout0.01_2...            0   \n",
       "18  1.596082  full_features_1cycle_NE_wdgs_wd1e-06_dropout0....        1e-06   \n",
       "17  1.596191  full_features_1cycle_NE_wdgs_wd1e-06_dropout0....        1e-06   \n",
       "14  1.596990  full_features_1cycle_NE_wdgs_wd1e-05_dropout0....        1e-05   \n",
       "5   1.597008  full_features_1cycle_NE_wdgs_wd0_dropout0.1_20...            0   \n",
       "2   1.597551  full_features_1cycle_NE_wdgs_wd1e-05_dropout0....        1e-05   \n",
       "15  1.599455  full_features_1cycle_NE_wdgs_wd1e-05_dropout0....        1e-05   \n",
       "8   1.602023  full_features_1cycle_NE_wdgs_wd0.0001_dropout0...       0.0001   \n",
       "11  1.607627  full_features_1cycle_NE_wdgs_wd0.001_dropout0....        0.001   \n",
       "1   1.616526  full_features_1cycle_NE_wdgs_wd1e-06_dropout0....        1e-06   \n",
       "\n",
       "   dropout  \n",
       "9      0.2  \n",
       "16     0.3  \n",
       "6      0.2  \n",
       "13     0.3  \n",
       "19     0.3  \n",
       "10     0.3  \n",
       "4     0.01  \n",
       "3     0.01  \n",
       "7      0.3  \n",
       "12     0.2  \n",
       "0     0.01  \n",
       "18     0.2  \n",
       "17     0.1  \n",
       "14     0.1  \n",
       "5      0.1  \n",
       "2     0.01  \n",
       "15     0.2  \n",
       "8      0.1  \n",
       "11     0.1  \n",
       "1     0.01  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performace.sort_values('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_decay</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>1.590730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.592489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-05</th>\n",
       "      <td>1.593749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>1.594802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-06</th>\n",
       "      <td>1.599771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  loss\n",
       "weight_decay          \n",
       "0.0001        1.590730\n",
       "0             1.592489\n",
       "1e-05         1.593749\n",
       "0.001         1.594802\n",
       "1e-06         1.599771"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performace.groupby(['weight_decay']).mean().sort_values('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_decay</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>1.590284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.591504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-05</th>\n",
       "      <td>1.592482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-06</th>\n",
       "      <td>1.594186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>1.595944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  loss\n",
       "weight_decay          \n",
       "0.0001        1.590284\n",
       "0             1.591504\n",
       "1e-05         1.592482\n",
       "1e-06         1.594186\n",
       "0.001         1.595944"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performace[model_performace.dropout.astype('float') >= 0.1].groupby(['weight_decay']).mean().sort_values('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.01</th>\n",
       "      <th>0</th>\n",
       "      <td>1.595447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>1.592070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>1.591376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-05</th>\n",
       "      <td>1.597551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-06</th>\n",
       "      <td>1.616526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.1</th>\n",
       "      <th>0</th>\n",
       "      <td>1.597008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>1.602023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>1.607627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-05</th>\n",
       "      <td>1.596990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-06</th>\n",
       "      <td>1.596191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.2</th>\n",
       "      <th>0</th>\n",
       "      <td>1.585259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>1.578437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>1.593640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-05</th>\n",
       "      <td>1.599455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-06</th>\n",
       "      <td>1.596082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.3</th>\n",
       "      <th>0</th>\n",
       "      <td>1.592244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>1.590392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>1.586565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-05</th>\n",
       "      <td>1.581001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e-06</th>\n",
       "      <td>1.590284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          loss\n",
       "dropout weight_decay          \n",
       "0.01    0             1.595447\n",
       "        0.0001        1.592070\n",
       "        0.001         1.591376\n",
       "        1e-05         1.597551\n",
       "        1e-06         1.616526\n",
       "0.1     0             1.597008\n",
       "        0.0001        1.602023\n",
       "        0.001         1.607627\n",
       "        1e-05         1.596990\n",
       "        1e-06         1.596191\n",
       "0.2     0             1.585259\n",
       "        0.0001        1.578437\n",
       "        0.001         1.593640\n",
       "        1e-05         1.599455\n",
       "        1e-06         1.596082\n",
       "0.3     0             1.592244\n",
       "        0.0001        1.590392\n",
       "        0.001         1.586565\n",
       "        1e-05         1.581001\n",
       "        1e-06         1.590284"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performace.groupby(['dropout', 'weight_decay']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>1.588097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>1.590575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>1.598594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>1.599968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss\n",
       "dropout          \n",
       "0.3      1.588097\n",
       "0.2      1.590575\n",
       "0.01     1.598594\n",
       "0.1      1.599968"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performace.groupby('dropout').mean().sort_values('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Decay Grid Search Conclusion\n",
    "\n",
    "**Weight Decay**: Use 1e-4 as the weight decay. Although There is a preference towards higher dropout and 1e-5 (with 0.3 dropout) performed the best, the overall trend indicates that 1e-4 would be the best for weight decay.\n",
    "\n",
    "**Dropout**: Although it may be specific to this architecture (the number of neurons in the first layer are roughly 4x that of the number of features so over-fitting may be an issue, though it is unclear due to the high-cardinal embeddings), there is a preference of higher dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_features(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search - Number of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_len_grid_search_iter(df, df_test, n_feat, arch, dropout, cycle_len, lr_ratio):\n",
    "        \n",
    "        # print progress\n",
    "        model_name = 'fm&p_1cycle_flgs_NO-METRIC_{}neurons_{}feats_{}dropout_{}cl_{}lrr_{}'.format('x'.join(str(_) for _ in arch),\n",
    "                                                                                         n_feat,\n",
    "                                                                                         dropout,\n",
    "                                                                                         cycle_len,\n",
    "                                                                                         lr_ratio,\n",
    "                                                                                         dt_str)\n",
    "        \n",
    "        # check if model has already been evaluated\n",
    "        if model_name not in already_done:\n",
    "            \n",
    "            print('\\n\\nStarting:', model_name, '\\n')\n",
    "\n",
    "            # set data based on feature importance\n",
    "            use_features = deepcopy(get_features(n_feat))\n",
    "            df = deepcopy(df[use_features])\n",
    "            df_test = deepcopy(df_test[use_features])\n",
    "\n",
    "            # init model objects\n",
    "            md = ColumnarModelData.from_data_frame(path = 'models', val_idxs = val_idx, df = df, y = yl.astype(np.float32),\n",
    "                                                   cat_flds = cat_vars, bs = 512, test_df = df_test)\n",
    "\n",
    "            m = md.get_learner(emb_szs = emb_szs, n_cont = len(df.columns) - len(cat_vars),\n",
    "                               emb_drop = 0.04, out_sz = 1, szs = arch, drops = [dropout for _ in arch], y_range = y_range)\n",
    "\n",
    "            # fit model\n",
    "            m.fit(lrs = 1e-4, n_cycle = 1, cycle_len = cycle_len,\n",
    "                  wds = 1e-4, use_wd_sched = True, use_clr_beta = (lr_ratio, 10, 0.95, 0.85),\n",
    "                  best_save_name = model_name)\n",
    "\n",
    "            del md, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx_filename = 'val_idx_saves/validation_idxs_2018-10-17-17-24-40.pkl'\n",
    "\n",
    "with open(val_idx_filename, \"rb\") as input_file:\n",
    "    val_idx = pickle.load(input_file)\n",
    "\n",
    "dt_str = val_idx_filename.split('_')[-1].split('.')[0]\n",
    "\n",
    "feature_lens = [100, 250, 500, int(df.shape[1])]\n",
    "\n",
    "archs = [\n",
    "    \n",
    "    # single layer\n",
    "    [2048], [8192], [16384],\n",
    "    \n",
    "    # two layer\n",
    "    [4096, 2048], [8192, 4096]\n",
    "    \n",
    "]\n",
    "\n",
    "lr_ratios = [10, 20]\n",
    "cycle_lens = [10, 20]\n",
    "\n",
    "dropouts = [0.01, 0.15, 0.30, 0.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_done = [\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_16384neurons_250feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40',\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_16384neurons_100feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40',\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_8192neurons_731feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40',\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_8192neurons_500feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40',\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_8192neurons_250feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40',\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_8192neurons_100feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40',\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_2048neurons_731feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40',\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_2048neurons_500feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40',\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_2048neurons_250feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40',\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_2048neurons_100feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr_ratio in lr_ratios:\n",
    "    for cycle_len in cycle_lens:\n",
    "        for dropout in dropouts:\n",
    "            for arch in archs:\n",
    "                for feat_len in feature_lens:\n",
    "                    \n",
    "                    # network grid search\n",
    "                    feat_len_grid_search_iter(df = df, df_test = df_test,\n",
    "                                              n_feat = feat_len, arch = arch, dropout = dropout,\n",
    "                                              cycle_len = cycle_len, lr_ratio = lr_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_get_val_loss(df, df_test, saved_weights, loc_val_idx):\n",
    "    \n",
    "    # set data based on feature importance\n",
    "    use_features = deepcopy(get_features(int(saved_weights.split('_')[5].replace('feats',''))))\n",
    "    df = deepcopy(df[use_features])\n",
    "    df_test = deepcopy(df_test[use_features])\n",
    "    \n",
    "    # init model objects\n",
    "    md = ColumnarModelData.from_data_frame(path = 'models', val_idxs = loc_val_idx, df = df,\n",
    "                                          y = yl.astype(np.float32), cat_flds = cat_vars,\n",
    "                                          bs = 512, test_df = df_test)\n",
    "    \n",
    "    # set params\n",
    "    arch_str = saved_weights.split('_')[4].replace('neurons','')\n",
    "    if 'x' in arch_str:\n",
    "        arch = [int(x) for x in arch_str.split('x')]\n",
    "    else:\n",
    "        arch = [int(arch_str)]\n",
    "    dropout = [float(saved_weights.split('_')[6].replace('dropout','')) for _ in range(len(arch))]\n",
    "    \n",
    "    # init model\n",
    "    m = md.get_learner(emb_szs = emb_szs, n_cont = len(df.columns) - len(cat_vars),\n",
    "                       emb_drop = 0.04, out_sz = 1, szs = arch, drops = dropout, y_range = y_range)\n",
    "    \n",
    "    # load saved weights\n",
    "    m.load(saved_weights)\n",
    "    \n",
    "    # calc rmse\n",
    "    yl_val = deepcopy(yl[loc_val_idx])\n",
    "    yl_hat = deepcopy(m.predict().reshape(-1,))\n",
    "    error = abs(neg_rmse(yl_hat, yl_val))\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting: fm&p_1cycle_flgs_NO-METRIC_16384neurons_250feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40\n",
      "starting: fm&p_1cycle_flgs_NO-METRIC_16384neurons_100feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40\n",
      "starting: fm&p_1cycle_flgs_NO-METRIC_8192neurons_731feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40\n",
      "starting: fm&p_1cycle_flgs_NO-METRIC_8192neurons_500feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40\n",
      "starting: fm&p_1cycle_flgs_NO-METRIC_8192neurons_250feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40\n",
      "starting: fm&p_1cycle_flgs_NO-METRIC_8192neurons_100feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40\n",
      "starting: fm&p_1cycle_flgs_NO-METRIC_2048neurons_731feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40\n",
      "starting: fm&p_1cycle_flgs_NO-METRIC_2048neurons_500feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40\n",
      "starting: fm&p_1cycle_flgs_NO-METRIC_2048neurons_250feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40\n",
      "starting: fm&p_1cycle_flgs_NO-METRIC_2048neurons_100feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40\n"
     ]
    }
   ],
   "source": [
    "overall_loss = {}\n",
    "for w in already_done:\n",
    "    \n",
    "    print('starting:', w)\n",
    "    \n",
    "    # get validation idxs\n",
    "    val_idx_filename = 'val_idx_saves/validation_idxs_{}.pkl'.format(w.split('_')[-1])\n",
    "    with open(val_idx_filename, \"rb\") as input_file:\n",
    "        testing_val_idx = pickle.load(input_file)\n",
    "    \n",
    "    overall_loss[w] = load_model_get_val_loss(df = df, df_test = df_test,\n",
    "                                              saved_weights = w, loc_val_idx = testing_val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performace = pd.DataFrame([deepcopy({'model': k, 'loss': v}) for k, v in overall_loss.items()])\n",
    "model_performace['neurons'] = model_performace['model'].apply(lambda x: x.split('_')[4].replace('neurons',''))\n",
    "model_performace['features'] = model_performace['model'].apply(lambda x: x.split('_')[5].replace('feats',''))\n",
    "model_performace['dropout'] = model_performace['model'].apply(lambda x: x.split('_')[6].replace('dropout',''))\n",
    "model_performace['cycle_len'] = model_performace['model'].apply(lambda x: x.split('_')[7].replace('cl',''))\n",
    "model_performace['lrr'] = model_performace['model'].apply(lambda x: x.split('_')[8].replace('lrr',''))\n",
    "model_performace['loss'] = deepcopy(abs(model_performace['loss']))\n",
    "model_performance = deepcopy(model_performace.sort_values('loss').reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_val_loss = {\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_2048neurons_100feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40': np.array([3.347684, 2.744391, 2.629406, 2.55512 , 2.567258, 2.555134, 2.520886, 2.523284, 2.523299, 2.522621  ]),\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_2048neurons_250feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40': np.array([3.095654, 2.697122, 2.653026, 2.531454, 2.544791, 2.552409, 2.477099, 2.47498 , 2.47375, 2.470464  ]),\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_2048neurons_500feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40': np.array([3.08827, 2.73723, 2.64565, 2.60124, 2.55610, 2.60442, 2.51611, 2.52958, 2.47141, 2.469996  ]),\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_2048neurons_731feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40': np.array([3.04271, 2.83798, 2.60379, 2.67048, 2.73475, 2.61827, 2.72725, 2.52010, 2.45680, 2.455631  ]),\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_8192neurons_100feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40': np.array([3.04698, 2.70211, 2.59508, 2.62172, 2.72411, 2.51314, 2.55092, 2.57755, 2.51459, 2.512478  ]),\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_8192neurons_250feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40': np.array([2.90848, 2.66609, 2.59221, 2.75509, 2.56533, 2.64999, 2.52613, 2.54765, 2.4780, 2.483123  ]),\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_8192neurons_500feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40': np.array([2.884043, 2.878907, 2.681378, 2.769486, 2.652656, 2.604965, 2.651284, 2.681571, 2.487437, 2.485724]),\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_8192neurons_731feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40': np.array([2.966291, 2.809198, 2.823968, 3.343454, 2.770357, 2.839633, 2.657642, 2.558284, 2.515352, 2.499695]),\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_16384neurons_100feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40': np.array([2.832378, 2.679827, 2.692498, 2.549022, 2.642235, 2.527256, 2.535636, 2.656356, 2.506931, 2.503804  ]),\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_16384neurons_250feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40': np.array([2.7638, 2.663342, 2.811103, 2.686378, 2.610389, 2.54054, 2.523607, 2.499045, 2.514366, 2.469489  ]),\n",
    "    'fm&p_1cycle_flgs_NO-METRIC_16384neurons_500feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40': np.array([2.737886, 2.860093, 2.906097, 2.752784, 2.877908, 2.921288, 2.70774, 2.552624, 2.523509, 2.505245])\n",
    "}\n",
    "\n",
    "model_performance = deepcopy(model_performance.merge(pd.DataFrame(\n",
    "    [deepcopy({'model': k, 'trn_loss': v.min()}) for k, v in manual_val_loss.items()]\n",
    "), on = 'model', how = 'left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>model</th>\n",
       "      <th>neurons</th>\n",
       "      <th>features</th>\n",
       "      <th>dropout</th>\n",
       "      <th>cycle_len</th>\n",
       "      <th>lrr</th>\n",
       "      <th>trn_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.567045</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_NO-METRIC_2048neurons_731feat...</td>\n",
       "      <td>2048</td>\n",
       "      <td>731</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2.455631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.571461</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_NO-METRIC_16384neurons_250fea...</td>\n",
       "      <td>16384</td>\n",
       "      <td>250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2.469489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.571622</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_NO-METRIC_2048neurons_500feat...</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2.469996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.571771</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_NO-METRIC_2048neurons_250feat...</td>\n",
       "      <td>2048</td>\n",
       "      <td>250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2.470464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.574191</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_NO-METRIC_8192neurons_250feat...</td>\n",
       "      <td>8192</td>\n",
       "      <td>250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2.478000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.576618</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_NO-METRIC_8192neurons_500feat...</td>\n",
       "      <td>8192</td>\n",
       "      <td>500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2.485724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.581043</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_NO-METRIC_8192neurons_731feat...</td>\n",
       "      <td>8192</td>\n",
       "      <td>731</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2.499695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.582341</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_NO-METRIC_16384neurons_100fea...</td>\n",
       "      <td>16384</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2.503804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.585080</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_NO-METRIC_8192neurons_100feat...</td>\n",
       "      <td>8192</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2.512478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.587730</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_NO-METRIC_2048neurons_100feat...</td>\n",
       "      <td>2048</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2.520886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss                                              model neurons  \\\n",
       "0  1.567045  fm&p_1cycle_flgs_NO-METRIC_2048neurons_731feat...    2048   \n",
       "1  1.571461  fm&p_1cycle_flgs_NO-METRIC_16384neurons_250fea...   16384   \n",
       "2  1.571622  fm&p_1cycle_flgs_NO-METRIC_2048neurons_500feat...    2048   \n",
       "3  1.571771  fm&p_1cycle_flgs_NO-METRIC_2048neurons_250feat...    2048   \n",
       "4  1.574191  fm&p_1cycle_flgs_NO-METRIC_8192neurons_250feat...    8192   \n",
       "5  1.576618  fm&p_1cycle_flgs_NO-METRIC_8192neurons_500feat...    8192   \n",
       "6  1.581043  fm&p_1cycle_flgs_NO-METRIC_8192neurons_731feat...    8192   \n",
       "7  1.582341  fm&p_1cycle_flgs_NO-METRIC_16384neurons_100fea...   16384   \n",
       "8  1.585080  fm&p_1cycle_flgs_NO-METRIC_8192neurons_100feat...    8192   \n",
       "9  1.587730  fm&p_1cycle_flgs_NO-METRIC_2048neurons_100feat...    2048   \n",
       "\n",
       "  features dropout cycle_len lrr  trn_loss  \n",
       "0      731    0.01        10  10  2.455631  \n",
       "1      250    0.01        10  10  2.469489  \n",
       "2      500    0.01        10  10  2.469996  \n",
       "3      250    0.01        10  10  2.470464  \n",
       "4      250    0.01        10  10  2.478000  \n",
       "5      500    0.01        10  10  2.485724  \n",
       "6      731    0.01        10  10  2.499695  \n",
       "7      100    0.01        10  10  2.503804  \n",
       "8      100    0.01        10  10  2.512478  \n",
       "9      100    0.01        10  10  2.520886  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance.sort_values('trn_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_len_grid_search_iter(df, df_test, n_feat, arch, dropout, cycle_len, lr_ratio):\n",
    "        \n",
    "        # print progress\n",
    "        model_name = 'fm&p_1cycle_flgs_{}neurons_{}feats_{}dropout_{}cl_{}lrr_{}'.format('x'.join(str(_) for _ in arch),\n",
    "                                                                                         n_feat,\n",
    "                                                                                         dropout,\n",
    "                                                                                         cycle_len,\n",
    "                                                                                         lr_ratio,\n",
    "                                                                                         dt_str)\n",
    "        \n",
    "        # check if model has already been evaluated\n",
    "        if model_name not in already_done:\n",
    "            \n",
    "            print('\\n\\nStarting:', model_name, '\\n')\n",
    "\n",
    "            # set data based on feature importance\n",
    "            use_features = deepcopy(get_features(n_feat))\n",
    "            df = deepcopy(df[use_features])\n",
    "            df_test = deepcopy(df_test[use_features])\n",
    "\n",
    "            # init model objects\n",
    "            md = ColumnarModelData.from_data_frame(path = 'models', val_idxs = val_idx, df = df, y = yl.astype(np.float32),\n",
    "                                                   cat_flds = cat_vars, bs = 512, test_df = df_test)\n",
    "\n",
    "            m = md.get_learner(emb_szs = emb_szs, n_cont = len(df.columns) - len(cat_vars),\n",
    "                               emb_drop = 0.04, out_sz = 1, szs = arch, drops = [dropout for _ in arch], y_range = y_range)\n",
    "\n",
    "            # fit model\n",
    "            m.fit(lrs = 1e-4, n_cycle = 1, cycle_len = cycle_len,\n",
    "                  wds = 1e-4, use_wd_sched = True, use_clr_beta = (lr_ratio, 10, 0.95, 0.85),\n",
    "                  metrics = [neg_rmse], best_save_name = model_name)\n",
    "\n",
    "            del md, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't redo any models that are already done\n",
    "with open('finshed_models.pkl', \"rb\") as f:\n",
    "    already_done = pickle.load(f)\n",
    "\n",
    "# get static val idxs\n",
    "val_idx_filename = 'val_idx_saves/validation_idxs_2018-10-17-17-24-40.pkl'\n",
    "with open(val_idx_filename, \"rb\") as f:\n",
    "    val_idx = pickle.load(f)\n",
    "dt_str = val_idx_filename.split('_')[-1].split('.')[0]\n",
    "\n",
    "# hyperparams\n",
    "feature_lens = [100, 250, 500, int(df.shape[1])]\n",
    "archs = [\n",
    "    [2048], [8192], [16384], # single layer\n",
    "    [4096, 2048], [8192, 4096] # two layer\n",
    "]\n",
    "lr_ratios = [10, 20]\n",
    "cycle_lens = [10, 20]\n",
    "dropouts = [0.01, 0.15, 0.30, 0.45]\n",
    "\n",
    "# search that grid!\n",
    "for lr_ratio in lr_ratios:\n",
    "    for cycle_len in cycle_lens:\n",
    "        for dropout in dropouts:\n",
    "            for arch in archs:\n",
    "                for feat_len in feature_lens:\n",
    "                    \n",
    "                    # network grid search\n",
    "                    feat_len_grid_search_iter(df = df, df_test = df_test,\n",
    "                                              n_feat = feat_len, arch = arch, dropout = dropout,\n",
    "                                              cycle_len = cycle_len, lr_ratio = lr_ratio)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Starting: fm&p_1cycle_flgs_2048neurons_100feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.318852   3.373875   -1.826505 \n",
    "    1      2.63563    2.775891   -1.654598 \n",
    "    2      2.510257   2.64547    -1.614346 \n",
    "    3      2.45356    2.543362   -1.583161 \n",
    "    4      2.551394   2.524933   -1.577409 \n",
    "    5      2.405689   2.503906   -1.570347 \n",
    "    6      2.242239   2.515927   -1.574233 \n",
    "    7      2.398696   2.503722   -1.570403 \n",
    "    8      2.109994   2.505664   -1.571008 \n",
    "    9      2.105677   2.507963   -1.571841 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_2048neurons_250feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.465011   3.335802   -1.81644  \n",
    "    1      2.634038   2.750324   -1.646844 \n",
    "    2      2.484714   2.613655   -1.605447 \n",
    "    3      2.530534   2.535706   -1.580925 \n",
    "    4      2.464857   2.556963   -1.587384 \n",
    "    5      2.382375   2.518953   -1.574874 \n",
    "    6      2.352885   2.513284   -1.574049 \n",
    "    7      2.236728   2.479014   -1.562431 \n",
    "    8      2.206811   2.488757   -1.565076 \n",
    "    9      2.172114   2.458874   -1.55614  \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_2048neurons_500feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.01314    3.145556   -1.762323 \n",
    "    1      2.630266   2.720534   -1.637082 \n",
    "    2      2.586309   2.753556   -1.646267 \n",
    "    3      2.438694   2.559642   -1.58782  \n",
    "    4      2.601235   2.588952   -1.59612  \n",
    "    5      2.312187   2.544444   -1.582175 \n",
    "    6      2.287728   2.531201   -1.578542 \n",
    "    7      2.147026   2.472484   -1.560244 \n",
    "    8      2.148761   2.458503   -1.556185 \n",
    "    9      2.1878     2.4582     -1.556072 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_2048neurons_731feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.050262   2.970456   -1.711775 \n",
    "    1      2.740051   2.753671   -1.646838 \n",
    "    2      2.835102   2.63592    -1.611794 \n",
    "    3      2.530074   2.743766   -1.643052 \n",
    "    4      2.649859   2.668327   -1.619555 \n",
    "    5      2.3489     2.574113   -1.59068  \n",
    "    6      2.337462   2.54995    -1.583814 \n",
    "    7      2.134886   2.539231   -1.580654 \n",
    "    8      2.169407   2.499395   -1.56806  \n",
    "    9      1.997436   2.462213   -1.556402 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192neurons_100feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.016689   2.925079   -1.699303 \n",
    "    1      2.628341   2.645224   -1.614516 \n",
    "    2      2.50501    2.55163    -1.585744 \n",
    "    3      2.37205    2.526977   -1.577591 \n",
    "    4      2.417229   2.632636   -1.610131 \n",
    "    5      2.491524   2.532898   -1.579893 \n",
    "    6      2.310696   2.528116   -1.578048 \n",
    "    7      2.264165   2.507863   -1.571611 \n",
    "    8      2.300345   2.505227   -1.571165 \n",
    "    9      2.144369   2.504231   -1.570904 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192neurons_250feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.781651   2.877669   -1.684504 \n",
    "    1      2.520354   2.671417   -1.622677 \n",
    "    2      2.653731   2.732204   -1.64054  \n",
    "    3      2.533272   2.786569   -1.654939 \n",
    "    4      2.671237   2.631016   -1.608478 \n",
    "    5      2.426104   2.668221   -1.620248 \n",
    "    6      2.30365    2.559577   -1.587628 \n",
    "    7      2.157786   2.518942   -1.574828 \n",
    "    8      2.170029   2.493722   -1.567155 \n",
    "    9      1.867117   2.475278   -1.561072 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192neurons_500feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.82052    2.864587   -1.680604 \n",
    "    1      2.553299   2.70256    -1.630759 \n",
    "    2      2.717685   2.676897   -1.622753 \n",
    "    3      2.621337   2.679079   -1.62274  \n",
    "    4      2.707059   2.735969   -1.640291 \n",
    "    5      2.479316   2.66376    -1.618739 \n",
    "    6      2.240765   2.829149   -1.667331 \n",
    "    7      2.318049   2.533193   -1.579905 \n",
    "    8      2.054349   2.526863   -1.576726 \n",
    "    9      2.028848   2.488603   -1.565214 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192neurons_731feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.989648   2.914507   -1.695041 \n",
    "    1      2.763907   3.189596   -1.770718 \n",
    "    2      2.796482   2.812416   -1.66171  \n",
    "    3      2.733233   2.739205   -1.639613 \n",
    "    4      2.697605   2.893702   -1.685779 \n",
    "    5      2.518827   2.739865   -1.639504 \n",
    "    6      2.305138   2.653921   -1.615163 \n",
    "    7      2.160191   2.54997    -1.583299 \n",
    "    8      2.078038   2.495932   -1.566421 \n",
    "    9      2.041474   2.479087   -1.561568 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_16384neurons_100feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.831859   2.905285   -1.692282 \n",
    "    1      2.612959   2.641542   -1.613163 \n",
    "    2      2.66138    2.678819   -1.625218 \n",
    "    3      2.564235   2.555375   -1.585911 \n",
    "    4      2.446508   2.590194   -1.595713 \n",
    "    5      2.545409   2.558218   -1.58865  \n",
    "    6      2.393558   2.587676   -1.596097 \n",
    "    7      2.253176   2.604079   -1.602312 \n",
    "    8      2.015719   2.505669   -1.57053  \n",
    "    9      2.037362   2.505951   -1.57091  \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_16384neurons_250feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.878672   2.85418    -1.677239 \n",
    "    1      2.668403   2.77215    -1.65356  \n",
    "    2      2.640587   2.6063     -1.601607 \n",
    "    3      2.704996   2.648006   -1.615322 \n",
    "    4      2.739889   2.660368   -1.61732  \n",
    "    5      2.549542   2.742883   -1.642985 \n",
    "    6      2.338288   2.549893   -1.584108 \n",
    "    7      2.080002   2.537341   -1.58078  \n",
    "    8      2.012147   2.487355   -1.56507  \n",
    "    9      1.905057   2.48231    -1.563581 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_16384neurons_500feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.909738   2.809803   -1.662918 \n",
    "    1      2.809927   2.87723    -1.680918 \n",
    "    2      2.78743    2.885271   -1.683662 \n",
    "    3      2.650326   2.768715   -1.648447 \n",
    "    4      2.897016   3.446489   -1.840262 \n",
    "    5      2.77596    2.726105   -1.636405 \n",
    "    6      2.403041   2.771765   -1.65037  \n",
    "    7      2.232841   2.592651   -1.596157 \n",
    "    8      2.157601   2.549158   -1.584043 \n",
    "    9      1.84464    2.536619   -1.580408 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_16384neurons_731feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.877489   2.909594   -1.692812 \n",
    "    1      2.869315   2.834457   -1.66952  \n",
    "    2      2.950469   2.872673   -1.679553 \n",
    "    3      3.090261   3.586424   -1.877719 \n",
    "    4      2.853217   2.907876   -1.690398 \n",
    "    5      2.473805   3.065344   -1.734594 \n",
    "    6      2.379464   2.666103   -1.61765  \n",
    "    7      2.180983   2.584592   -1.593282 \n",
    "    8      2.110703   2.595402   -1.597921 \n",
    "    9      1.911137   2.544614   -1.582029 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_100feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.890163   4.1043     -2.008551 \n",
    "    1      2.724439   2.622329   -1.60904  \n",
    "    2      2.44534    2.633768   -1.609756 \n",
    "    3      2.568739   2.538688   -1.581847 \n",
    "    4      2.524043   2.50471    -1.57161  \n",
    "    5      2.289829   2.504897   -1.570656 \n",
    "    6      2.290247   2.545885   -1.582384 \n",
    "    7      2.102496   2.472646   -1.559744 \n",
    "    8      2.000217   2.457847   -1.554627 \n",
    "    9      1.849925   2.459087   -1.555651 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_250feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.895238   4.090936   -2.005286 \n",
    "    1      2.829335   2.689314   -1.628361 \n",
    "    2      2.635277   2.589451   -1.595034 \n",
    "    3      2.504801   2.547602   -1.582832 \n",
    "    4      2.282221   2.492651   -1.567493 \n",
    "    5      2.418948   2.440181   -1.550662 \n",
    "    6      2.167251   2.441771   -1.549221 \n",
    "    7      1.971691   2.416378   -1.540016 \n",
    "    8      1.836153   2.401237   -1.536735 \n",
    "    9      1.827194   2.395183   -1.534662 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_500feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.157535   2.959058   -1.705644 \n",
    "    1      2.807361   2.782436   -1.653853 \n",
    "    2      2.618782   2.707419   -1.631287 \n",
    "    3      2.492913   2.58255    -1.593755 \n",
    "    4      2.350858   2.628197   -1.607362 \n",
    "    5      2.44391    2.45017    -1.553601 \n",
    "    6      2.424918   2.464475   -1.557571 \n",
    "    7      2.05297    2.446401   -1.551754 \n",
    "    8      1.852377   2.458145   -1.555021 \n",
    "    9      1.6861     2.453151   -1.553618 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_731feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.89887    4.096887   -2.00676  \n",
    "    1      2.853373   2.967556   -1.708164 \n",
    "    2      2.750835   2.774846   -1.650877 \n",
    "    3      2.630335   2.601398   -1.600943 \n",
    "    4      2.525553   2.549147   -1.584685 \n",
    "    5      2.356077   2.479185   -1.562735 \n",
    "    6      2.351092   2.488385   -1.565539 \n",
    "    7      2.107169   2.438399   -1.548206 \n",
    "    8      2.005544   2.44813    -1.552002 \n",
    "    9      1.797406   2.453686   -1.553781 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192x4096neurons_100feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.945777   4.106436   -2.009013 \n",
    "    1      3.055414   2.902148   -1.688738 \n",
    "    2      2.531355   2.707871   -1.632357 \n",
    "    3      2.513594   2.541956   -1.583856 \n",
    "    4      2.453843   2.499418   -1.568933 \n",
    "    5      2.308207   2.465377   -1.55765  \n",
    "    6      2.340828   2.474613   -1.561673 \n",
    "    7      2.0747     2.436774   -1.54833  \n",
    "    8      1.962646   2.439513   -1.549053 \n",
    "    9      1.849386   2.435327   -1.547981 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192x4096neurons_250feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.156541   4.108429   -2.009493 \n",
    "    1      3.982443   4.10769    -2.009313 \n",
    "    2      4.150922   4.108475   -2.009501 \n",
    "    3      4.02427    4.108414   -2.009487 \n",
    "    4      3.907075   4.108517   -2.009512 \n",
    "    5      3.92123    4.108517   -2.009512 \n",
    "    6      4.267692   4.108517   -2.009512 \n",
    "    7      4.019268   4.108517   -2.009512 \n",
    "    8      3.908957   4.108517   -2.009512 \n",
    "    9      3.728976   4.108517   -2.009512 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192x4096neurons_500feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.735946   4.10847    -2.009503 \n",
    "    1      4.232977   4.108259   -2.009451 \n",
    "    2      3.971004   4.108444   -2.009495 \n",
    "    3      4.007038   4.108114   -2.009416 \n",
    "    4      4.153906   4.108517   -2.009512 \n",
    "    5      4.0227     4.108517   -2.009512 \n",
    "    6      4.295168   4.108517   -2.009512 \n",
    "    7      4.035816   4.108517   -2.009512 \n",
    "    8      4.080701   4.108517   -2.009512 \n",
    "    9      3.963279   4.108517   -2.009512 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192x4096neurons_731feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.109288   4.108517   -2.009513 \n",
    "    1      4.06705    4.108468   -2.009501 \n",
    "    2      3.941373   4.10775    -2.009328 \n",
    "    3      3.807948   4.108516   -2.009512 \n",
    "    4      3.870235   4.108512   -2.009511 \n",
    "    5      4.206485   4.1085     -2.009508 \n",
    "    6      3.999614   4.108521   -2.009513 \n",
    "    7      3.760263   4.108521   -2.009513 \n",
    "    8      4.20698    4.108523   -2.009513 \n",
    "    9      4.047174   4.108537   -2.009517 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_2048neurons_100feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.394669   3.325049   -1.813259 \n",
    "    1      2.788883   2.775228   -1.653692 \n",
    "    2      2.626569   2.617002   -1.606638 \n",
    "    3      2.62921    2.54356    -1.583365 \n",
    "    4      2.433179   2.529215   -1.579273 \n",
    "    5      2.56672    2.561578   -1.589383 \n",
    "    6      2.39634    2.498319   -1.568855 \n",
    "    7      2.420724   2.508343   -1.572222 \n",
    "    8      2.322667   2.512255   -1.573413 \n",
    "    9      2.474846   2.501246   -1.569734 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_2048neurons_250feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.498223   3.327632   -1.813384 \n",
    "    1      2.888996   2.767944   -1.651974 \n",
    "    2      2.686481   2.703928   -1.63191  \n",
    "    3      2.770776   2.765973   -1.649997 \n",
    "    4      2.68151    2.556477   -1.587108 \n",
    "    5      2.505433   2.513777   -1.573025 \n",
    "    6      2.484873   2.514506   -1.574095 \n",
    "    7      2.348319   2.517184   -1.575125 \n",
    "    8      2.147581   2.486942   -1.565527 \n",
    "    9      2.290324   2.475078   -1.56163  \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_2048neurons_500feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.338436   3.215591   -1.78201  \n",
    "    1      2.804566   2.790549   -1.657899 \n",
    "    2      2.829445   2.702121   -1.630566 \n",
    "    3      2.592975   2.656259   -1.617643 \n",
    "    4      2.587944   2.659846   -1.617331 \n",
    "    5      2.391425   2.558322   -1.587355 \n",
    "    6      2.35359    2.493855   -1.566175 \n",
    "    7      2.279599   2.46337    -1.557066 \n",
    "    8      2.221959   2.45001    -1.552765 \n",
    "    9      2.188614   2.44885    -1.552569 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_2048neurons_731feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.375018   3.146807   -1.761995 \n",
    "    1      2.929581   2.765549   -1.650634 \n",
    "    2      2.783836   2.931335   -1.698426 \n",
    "    3      2.699713   2.796319   -1.658969 \n",
    "    4      2.697552   2.634806   -1.610068 \n",
    "    5      2.4875     2.605152   -1.601487 \n",
    "    6      2.241974   2.518345   -1.573896 \n",
    "    7      2.215352   2.496447   -1.566925 \n",
    "    8      2.347711   2.475779   -1.561717 \n",
    "    9      2.036098   2.456452   -1.555093 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192neurons_100feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.225684   3.052441   -1.735706 \n",
    "    1      2.633723   2.65297    -1.617216 \n",
    "    2      2.562412   2.557493   -1.587775 \n",
    "    3      2.446527   2.564992   -1.58891  \n",
    "    4      2.381866   2.5874     -1.595809 \n",
    "    5      2.411454   2.59296    -1.598249 \n",
    "    6      2.282219   2.539717   -1.582359 \n",
    "    7      2.30154    2.542902   -1.583285 \n",
    "    8      2.23097    2.513609   -1.573208 \n",
    "    9      2.27823    2.50805    -1.571678 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192neurons_250feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.873985   2.894546   -1.689172 \n",
    "    1      2.65714    2.685952   -1.626532 \n",
    "    2      2.831328   2.931833   -1.697457 \n",
    "    3      2.77605    2.783573   -1.654019 \n",
    "    4      2.630594   2.742111   -1.641952 \n",
    "    5      2.429628   2.606111   -1.600155 \n",
    "    6      2.328271   2.61161    -1.602406 \n",
    "    7      2.326354   2.589688   -1.596234 \n",
    "    8      2.098647   2.487562   -1.564781 \n",
    "    9      2.449285   2.478762   -1.562198 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192neurons_500feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.107101   2.913463   -1.694257 \n",
    "    1      2.819281   2.69777    -1.629769 \n",
    "    2      2.920206   2.810377   -1.663124 \n",
    "    3      2.788352   2.986062   -1.713093 \n",
    "    4      2.746764   2.726008   -1.636353 \n",
    "    5      2.52434    2.610534   -1.602192 \n",
    "    6      2.446763   2.764323   -1.647599 \n",
    "    7      2.343188   2.52815    -1.577473 \n",
    "    8      2.29962    2.530645   -1.578253 \n",
    "    9      2.005744   2.496915   -1.567647 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192neurons_731feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.888971   2.947174   -1.703329 \n",
    "    1      3.107792   3.334791   -1.810717 \n",
    "    2      2.947595   2.957069   -1.703934 \n",
    "    3      2.907264   2.926278   -1.695217 \n",
    "    4      2.781      2.799553   -1.658209 \n",
    "    5      2.707774   2.751374   -1.644772 \n",
    "    6      2.47601    2.601305   -1.597981 \n",
    "    7      2.279909   2.540264   -1.580246 \n",
    "    8      2.160891   2.502519   -1.569353 \n",
    "    9      2.123458   2.471343   -1.559216 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_16384neurons_100feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.031979   2.919316   -1.697175 \n",
    "    1      2.77253    2.625024   -1.608993 \n",
    "    2      2.5613     2.541515   -1.582374 \n",
    "    3      2.560424   2.840333   -1.671934 \n",
    "    4      2.558832   2.582858   -1.593631 \n",
    "    5      2.321439   2.582458   -1.595235 \n",
    "    6      2.236626   2.670543   -1.620475 \n",
    "    7      2.340625   2.545416   -1.582972 \n",
    "    8      2.234318   2.523941   -1.576408 \n",
    "    9      2.04024    2.528638   -1.5783   \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_16384neurons_250feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.897086   2.77349    -1.653185 \n",
    "    1      2.686332   2.643168   -1.613314 \n",
    "    2      2.711456   2.631482   -1.60934  \n",
    "    3      2.604675   2.671648   -1.619354 \n",
    "    4      2.755544   2.677833   -1.622371 \n",
    "    5      2.631083   2.607571   -1.601322 \n",
    "    6      2.39395    2.530806   -1.577704 \n",
    "    7      2.241999   2.519455   -1.575341 \n",
    "    8      2.07539    2.511717   -1.572297 \n",
    "    9      2.108183   2.483112   -1.563615 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_16384neurons_500feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.986634   2.767131   -1.650819 \n",
    "    1      2.808421   2.823148   -1.665698 \n",
    "    2      2.781561   2.714588   -1.632696 \n",
    "    3      2.941783   2.934566   -1.696629 \n",
    "    4      2.644028   2.93932    -1.697998 \n",
    "    5      2.539823   2.722892   -1.636755 \n",
    "    6      2.310728   2.734114   -1.638755 \n",
    "    7      2.210935   2.564585   -1.587015 \n",
    "    8      2.161007   2.521226   -1.574606 \n",
    "    9      2.046124   2.493009   -1.566099 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_16384neurons_731feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.910492   2.919322   -1.694574 \n",
    "    1      3.094106   2.767037   -1.64934  \n",
    "    2      2.969032   3.143975   -1.757522 \n",
    "    3      3.058475   3.223465   -1.778455 \n",
    "    4      2.919372   2.993679   -1.714024 \n",
    "    5      2.621451   2.874353   -1.677929 \n",
    "    6      2.44164    2.673016   -1.620661 \n",
    "    7      2.349281   2.623234   -1.605254 \n",
    "    8      2.317382   2.529948   -1.577555 \n",
    "    9      2.002603   2.502141   -1.568617 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_100feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.07923    2.962039   -1.708118 \n",
    "    1      2.694044   2.612051   -1.60513  \n",
    "    2      2.537561   2.758026   -1.646943 \n",
    "    3      2.542274   2.690089   -1.629377 \n",
    "    4      2.432461   2.494193   -1.566948 \n",
    "    5      2.396273   2.485179   -1.56322  \n",
    "    6      2.26306    2.477762   -1.5621   \n",
    "    7      2.318724   2.455499   -1.554913 \n",
    "    8      2.151558   2.451042   -1.553705 \n",
    "    9      2.133569   2.450793   -1.553476 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_250feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.17771    4.109325   -2.009817 \n",
    "    1      2.826936   2.792441   -1.658363 \n",
    "    2      2.733203   2.790076   -1.65601  \n",
    "    3      2.472723   2.790453   -1.658707 \n",
    "    4      2.46554    2.578216   -1.593518 \n",
    "    5      2.472514   2.479744   -1.564191 \n",
    "    6      2.446825   2.44162    -1.550686 \n",
    "    7      2.150728   2.423349   -1.543653 \n",
    "    8      2.017851   2.393601   -1.534527 \n",
    "    9      2.106203   2.394235   -1.534712 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_500feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.024596   4.110011   -2.009976 \n",
    "    1      3.048758   2.951895   -1.704444 \n",
    "    2      2.760305   2.733824   -1.640513 \n",
    "    3      2.787814   2.74461    -1.644224 \n",
    "    4      2.507075   2.619121   -1.606269 \n",
    "    5      2.435712   2.513278   -1.57359  \n",
    "    6      2.414189   2.482881   -1.563104 \n",
    "    7      2.332545   2.479097   -1.563039 \n",
    "    8      2.066305   2.438579   -1.549285 \n",
    "    9      1.918964   2.442148   -1.550508 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_731feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.586764   3.423261   -1.834826 \n",
    "    1      3.100597   2.882922   -1.684132 \n",
    "    2      2.684812   2.671922   -1.622768 \n",
    "    3      2.740421   2.673404   -1.624112 \n",
    "    4      2.423302   2.591039   -1.596288 \n",
    "    5      2.508083   2.505975   -1.570556 \n",
    "    6      2.314563   2.483373   -1.563507 \n",
    "    7      2.304034   2.464922   -1.557265 \n",
    "    8      2.184218   2.424727   -1.544903 \n",
    "    9      2.05572    2.421649   -1.543639 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192x4096neurons_100feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.007241   4.109624   -2.009807 \n",
    "    1      3.250711   3.768062   -1.924568 \n",
    "    2      2.64204    2.71537    -1.634523 \n",
    "    3      2.563648   2.609676   -1.602282 \n",
    "    4      2.370627   2.630902   -1.609073 \n",
    "    5      2.274667   2.482568   -1.563568 \n",
    "    6      2.261009   2.483113   -1.562899 \n",
    "    7      2.173766   2.475455   -1.561373 \n",
    "    8      2.201752   2.472706   -1.560016 \n",
    "    9      2.015327   2.46179    -1.556761 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192x4096neurons_250feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.890265   4.109046   -2.009648 \n",
    "    1      4.04835    4.108706   -2.009562 \n",
    "    2      4.133609   4.108452   -2.009498 \n",
    "    3      4.218036   4.10852    -2.009513 \n",
    "    4      3.790344   4.10852    -2.009512 \n",
    "    5      3.893439   4.108519   -2.009512 \n",
    "    6      4.053251   4.108518   -2.009512 \n",
    "    7      3.91133    4.108518   -2.009512 \n",
    "    8      4.408884   4.108517   -2.009512 \n",
    "    9      4.02736    4.108517   -2.009512 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192x4096neurons_500feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.291774   4.108596   -2.009534 \n",
    "    1      3.82493    4.108525   -2.009516 \n",
    "    2      3.936345   4.108342   -2.009471 \n",
    "    3      3.918111   4.108517   -2.009512 \n",
    "    4      4.074942   4.108517   -2.009512 \n",
    "    5      3.920839   4.108517   -2.009512 \n",
    "    6      4.042698   4.108517   -2.009512 \n",
    "    7      3.822871   4.108517   -2.009512 \n",
    "    8      4.163599   4.108517   -2.009512 \n",
    "    9      4.196759   4.108517   -2.009512 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192x4096neurons_731feats_0.15dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.931116   4.108479   -2.009503 \n",
    "    1      4.004438   4.108458   -2.009498 \n",
    "    2      4.08329    4.108308   -2.009462 \n",
    "    3      4.005591   4.108516   -2.009512 \n",
    "    4      4.282234   4.108516   -2.009512 \n",
    "    5      4.027963   4.108516   -2.009512 \n",
    "    6      3.948631   4.108516   -2.009512 \n",
    "    7      4.158051   4.108516   -2.009512 \n",
    "    8      4.246749   4.108516   -2.009512 \n",
    "    9      3.952      4.108516   -2.009512 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_2048neurons_100feats_0.3dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.309818   3.241012   -1.789454 \n",
    "    1      2.987174   2.73743    -1.642576 \n",
    "    2      2.649254   2.61611    -1.605537 \n",
    "    3      2.659185   2.633656   -1.611093 \n",
    "    4      2.686322   2.527053   -1.577717 \n",
    "    5      2.43403    2.510765   -1.572714 \n",
    "    6      2.449998   2.519099   -1.575396 \n",
    "    7      2.360258   2.512309   -1.573131 \n",
    "    8      2.303745   2.505611   -1.570802 \n",
    "    9      2.370527   2.504027   -1.570613 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_2048neurons_250feats_0.3dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.43843    3.363014   -1.822567 \n",
    "    1      2.987654   2.790555   -1.657952 \n",
    "    2      2.707552   2.641753   -1.613214 \n",
    "    3      2.66882    2.585619   -1.59532  \n",
    "    4      2.659199   2.580519   -1.593682 \n",
    "    5      2.500922   2.520423   -1.575393 \n",
    "    6      2.308646   2.523734   -1.576751 \n",
    "    7      2.335654   2.485428   -1.564685 \n",
    "    8      2.346348   2.472788   -1.560596 \n",
    "    9      2.19892    2.471904   -1.560327 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_2048neurons_500feats_0.3dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.240895   3.194065   -1.775044 \n",
    "    1      2.968092   2.776178   -1.653253 \n",
    "    2      2.795641   2.807612   -1.66188  \n",
    "    3      2.738981   2.787066   -1.656192 \n",
    "    4      2.68739    2.564351   -1.58874  \n",
    "    5      2.511654   2.549197   -1.583983 \n",
    "    6      2.405975   2.500561   -1.568276 \n",
    "    7      2.326089   2.501502   -1.568784 \n",
    "    8      2.212853   2.471187   -1.559953 \n",
    "    9      2.193466   2.462793   -1.55727  \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_2048neurons_731feats_0.3dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.26038    3.258711   -1.791684 \n",
    "    1      3.057958   2.830704   -1.669612 \n",
    "    2      3.117188   2.736791   -1.641205 \n",
    "    3      2.888371   2.710973   -1.634692 \n",
    "    4      2.811673   2.723486   -1.636526 \n",
    "    5      2.422925   2.570951   -1.590726 \n",
    "    6      2.248326   2.525327   -1.576253 \n",
    "    7      2.229043   2.49416    -1.566729 \n",
    "    8      2.405488   2.493328   -1.566652 \n",
    "    9      2.291662   2.480154   -1.562186 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192neurons_100feats_0.3dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.99165    2.928975   -1.70001  \n",
    "    1      2.693379   2.695033   -1.629562 \n",
    "    2      2.757737   2.600111   -1.600448 \n",
    "    3      2.566749   2.602189   -1.601749 \n",
    "    4      2.573411   2.56302    -1.58902  \n",
    "    5      2.684779   2.554542   -1.585516 \n",
    "    6      2.546902   2.536601   -1.580319 \n",
    "    7      2.352893   2.543086   -1.582305 \n",
    "    8      2.371503   2.519653   -1.575143 \n",
    "    9      2.187076   2.514481   -1.573627 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192neurons_250feats_0.3dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.185514   2.882443   -1.685752 \n",
    "    1      2.877866   2.665898   -1.619903 \n",
    "    2      2.814774   2.61421    -1.604707 \n",
    "    3      2.512206   2.629694   -1.608192 \n",
    "    4      2.79637    2.631106   -1.608493 \n",
    "    5      2.464591   2.603196   -1.600152 \n",
    "    6      2.260752   2.541619   -1.581808 \n",
    "    7      2.208813   2.514952   -1.572659 \n",
    "    8      2.30248    2.474111   -1.560123 \n",
    "    9      2.167654   2.457276   -1.555127 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192neurons_500feats_0.3dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.086689   2.98986    -1.715541 \n",
    "    1      2.952099   2.830624   -1.668478 \n",
    "    2      2.786934   2.723049   -1.636289 \n",
    "    3      2.700096   2.724479   -1.636456 \n",
    "    4      2.694337   2.932363   -1.697172 \n",
    "    5      2.478921   2.708561   -1.631061 \n",
    "    6      2.402301   2.547881   -1.582485 \n",
    "    7      2.19891    2.51485    -1.572824 \n",
    "    8      2.208598   2.49408    -1.566941 \n",
    "    9      2.229461   2.472855   -1.559957 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192neurons_731feats_0.3dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.095434   2.895282   -1.688057 \n",
    "    1      3.229466   2.820003   -1.664755 \n",
    "    2      3.264722   2.821344   -1.665342 \n",
    "    3      2.962119   2.997721   -1.716245 \n",
    "    4      2.770439   2.683131   -1.622566 \n",
    "    5      2.673184   2.718239   -1.634444 \n",
    "    6      2.417585   2.592547   -1.597274 \n",
    "    7      2.446916   2.545275   -1.581082 \n",
    "    8      2.140706   2.484998   -1.56333  \n",
    "    9      2.158883   2.468052   -1.557983 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_16384neurons_100feats_0.3dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.252891   2.895848   -1.690169 \n",
    "    1      2.831385   2.706771   -1.633586 \n",
    "    2      2.783433   2.560833   -1.588907 \n",
    "    3      2.807938   2.551182   -1.585218 \n",
    "    4      2.452927   2.579834   -1.593828 \n",
    "    5      2.384793   2.672268   -1.621206 \n",
    "    6      2.366093   2.566342   -1.588927 \n",
    "    7      2.266998   2.629175   -1.607967 \n",
    "    8      2.032144   2.520173   -1.575016 \n",
    "    9      2.237588   2.511291   -1.572597 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_16384neurons_250feats_0.3dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.99291    3.139217   -1.757692 \n",
    "    1      2.99606    2.695448   -1.629267 \n",
    "    2      2.774151   2.78204    -1.654004 \n",
    "    3      2.97634    3.46928    -1.846096 \n",
    "    4      2.775327   2.672713   -1.620509 \n",
    "    5      2.700099   2.619565   -1.604673 \n",
    "    6      2.375273   2.61759    -1.60382  \n",
    "    7      2.419211   2.525951   -1.576683 \n",
    "    8      2.180098   2.527529   -1.577259 \n",
    "    9      2.1917     2.488948   -1.565212 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_16384neurons_500feats_0.3dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.030382   2.926888   -1.696794 \n",
    "    1      3.138416   2.939403   -1.699838 \n",
    "    2      3.058703   2.809776   -1.661327 \n",
    "    3      3.086558   2.822101   -1.663369 \n",
    "    4      2.894316   2.720955   -1.633108 \n",
    "    5      2.57651    2.643513   -1.611869 \n",
    "    6      2.383483   2.557867   -1.585499 \n",
    "    7      2.299534   2.593081   -1.595661 \n",
    "    8      2.011375   2.507761   -1.569992 \n",
    "    9      2.146778   2.498559   -1.567529 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_16384neurons_731feats_0.3dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.945196   2.901409   -1.688152 \n",
    "    1      2.985715   2.937203   -1.699243 \n",
    "    2      3.003977   3.19794    -1.771807 \n",
    "    3      3.569916   3.844823   -1.943884 \n",
    "    4      3.124893   3.178108   -1.765915 \n",
    "    5      2.835904   2.821306   -1.663405 \n",
    "    6      2.463965   2.649563   -1.61261  \n",
    "    7      2.3917     2.642132   -1.610985 \n",
    "    8      2.235655   2.540005   -1.579864 \n",
    "    9      2.067551   2.501212   -1.568147 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_100feats_0.3dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.370591   4.105495   -2.008878 \n",
    "    1      2.796213   2.761816   -1.650659 \n",
    "    2      2.709981   2.673742   -1.624913 \n",
    "    3      2.606914   2.689606   -1.629544 \n",
    "    4      2.513343   2.546481   -1.58535  \n",
    "    5      2.420772   2.479674   -1.563212 \n",
    "    6      2.494224   2.468477   -1.56006  \n",
    "    7      2.271862   2.473078   -1.560489 \n",
    "    8      2.251662   2.455428   -1.555554 \n",
    "    9      2.306162   2.453669   -1.554775 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_250feats_0.3dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.988019   4.111324   -2.010285 \n",
    "    1      3.23813    2.824381   -1.667119 \n",
    "    2      2.832464   2.796612   -1.659127 \n",
    "    3      2.484347   2.593263   -1.599642 \n",
    "    4      2.473439   2.567867   -1.590245 \n",
    "    5      2.488455   2.514623   -1.574007 \n",
    "    6      2.333504   2.518929   -1.576286 \n",
    "    7      2.266345   2.428809   -1.546889 \n",
    "    8      2.298219   2.431802   -1.548086 \n",
    "    9      2.139581   2.427949   -1.546661 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_500feats_0.3dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.908844   4.105334   -2.008829 \n",
    "    1      3.114144   2.863483   -1.679182 \n",
    "    2      2.783558   2.89693    -1.688973 \n",
    "    3      2.733124   2.653051   -1.615703 \n",
    "    4      2.664813   2.544813   -1.584427 \n",
    "    5      2.439181   2.579977   -1.594527 \n",
    "    6      2.451632   2.462478   -1.55726  \n",
    "    7      2.364924   2.433569   -1.548405 \n",
    "    8      2.095712   2.415153   -1.542378 \n",
    "    9      2.288045   2.425537   -1.545953 \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_731feats_0.3dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.811477   3.997024   -1.982147 \n",
    "    1      3.305938   3.077494   -1.739618 \n",
    "    2      2.993359   2.763241   -1.650436 \n",
    "    3      2.690612   2.673848   -1.62425  \n",
    "    4      2.576807   2.61402    -1.603549 \n",
    "    5      2.478232   2.501307   -1.56943  \n",
    "    6      2.16233    2.499997   -1.568456 \n",
    "    7      2.292018   2.422815   -1.544759 \n",
    "    8      2.318024   2.425157   -1.545358 \n",
    "    9      2.255206   2.424528   -1.54543  \n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192x4096neurons_100feats_0.3dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.925869   4.109133   -2.009696 \n",
    "    1      3.195784   3.084869   -1.74244  \n",
    "    2      3.038549   2.83808    -1.674223 \n",
    "    3      2.804914   2.616183   -1.60693  \n",
    "    4      2.512523   2.581813   -1.595768 \n",
    "    5      2.404588   2.497676   -1.569234 \n",
    "    6      2.32589    2.480167   -1.563616 \n",
    "    7      2.390483   2.489123   -1.565042 \n",
    "    8      2.168089   2.464705   -1.557763 \n",
    "    9      2.156597   2.464973   -1.557884 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_2048neurons_100feats_0.01dropout_10cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.463359   3.393268   -1.831911 \n",
    "    1      2.885004   2.787322   -1.657944 \n",
    "    2      2.757094   2.677592   -1.625669 \n",
    "    3      2.573699   2.559788   -1.58849  \n",
    "    4      2.478451   2.578724   -1.593634 \n",
    "    5      2.352297   2.588507   -1.596301 \n",
    "    6      2.400071   2.529908   -1.579418 \n",
    "    7      2.223037   2.52167    -1.575907 \n",
    "    8      2.194933   2.521624   -1.576238 \n",
    "    9      2.227709   2.524251   -1.577199 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_100feats_0.01dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.80369    2.83193    -1.671545 \n",
    "    1      2.826672   2.617516   -1.607153 \n",
    "    2      2.731427   2.588168   -1.598148 \n",
    "    3      2.427981   2.497573   -1.569213 \n",
    "    4      2.443765   2.587626   -1.597121 \n",
    "    5      2.494809   2.615924   -1.604625 \n",
    "    6      2.212962   2.477336   -1.561199 \n",
    "    7      2.250908   2.489989   -1.5656   \n",
    "    8      2.175119   2.512398   -1.572039 \n",
    "    9      2.13745    2.550981   -1.585233 \n",
    "    10     2.05993    2.534294   -1.580016 \n",
    "    11     1.9631     2.555343   -1.585174 \n",
    "    12     1.861143   2.623963   -1.60565  \n",
    "    13     1.747034   2.613419   -1.603185 \n",
    "    14     1.657758   2.688633   -1.624275 \n",
    "    15     1.462183   2.765243   -1.648381 \n",
    "    16     1.394509   2.705079   -1.630263 \n",
    "    17     1.387438   2.738863   -1.640411 \n",
    "    18     1.298725   2.777849   -1.65229  \n",
    "    19     1.366829   2.750271   -1.643715 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_250feats_0.01dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.069512   4.105988   -2.009023 \n",
    "    1      2.908575   2.792013   -1.65769  \n",
    "    2      2.718792   2.830012   -1.668145 \n",
    "    3      2.65364    2.660792   -1.618062 \n",
    "    4      2.539483   2.560038   -1.586646 \n",
    "    5      2.472026   2.51676    -1.573908 \n",
    "    6      2.377213   2.602141   -1.599734 \n",
    "    7      2.409902   2.691322   -1.627848 \n",
    "    8      2.39361    2.540666   -1.580828 \n",
    "    9      2.151313   2.497901   -1.567696 \n",
    "    10     2.163019   2.486561   -1.562139 \n",
    "    11     1.974903   2.528457   -1.577143 \n",
    "    12     1.810558   2.536229   -1.578351 \n",
    "    13     1.795058   2.554715   -1.584304 \n",
    "    14     1.541093   2.65216    -1.614212 \n",
    "    15     1.494339   2.664813   -1.618299 \n",
    "    16     1.383134   2.6415     -1.610559 \n",
    "    17     1.347423   2.695311   -1.627491 \n",
    "    18     1.189869   2.666264   -1.618385 \n",
    "    19     1.202683   2.680712   -1.622766 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_500feats_0.01dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.215225   4.10115    -2.007827 \n",
    "    1      2.693776   2.891154   -1.686636 \n",
    "    2      2.96913    2.599113   -1.599691 \n",
    "    3      2.484726   2.632501   -1.608136 \n",
    "    4      2.645499   2.573688   -1.592288 \n",
    "    5      2.573237   2.526503   -1.577893 \n",
    "    6      2.473251   2.621751   -1.606136 \n",
    "    7      2.209737   2.570342   -1.589211 \n",
    "    8      2.287278   2.649162   -1.615164 \n",
    "    9      2.053927   2.592526   -1.596089 \n",
    "    10     2.108998   2.493793   -1.5659   \n",
    "    11     1.883012   2.629214   -1.607761 \n",
    "    12     1.815719   2.610731   -1.600437 \n",
    "    13     1.596347   2.607656   -1.59963  \n",
    "    14     1.401646   2.64285    -1.610923 \n",
    "    15     1.378444   2.701444   -1.629178 \n",
    "    16     1.255461   2.741735   -1.641435 \n",
    "    17     1.026737   2.760334   -1.646662 \n",
    "    18     0.912537   2.7558     -1.645119 \n",
    "    19     1.017746   2.757169   -1.6456   \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_731feats_0.01dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.940558   4.109437   -2.009847 \n",
    "    1      3.034404   2.958591   -1.707449 \n",
    "    2      2.713525   2.859736   -1.677653 \n",
    "    3      2.592352   2.794824   -1.657351 \n",
    "    4      2.714169   2.656534   -1.617009 \n",
    "    5      2.712286   2.600096   -1.600329 \n",
    "    6      2.437681   2.551873   -1.586527 \n",
    "    7      2.239494   2.716754   -1.633246 \n",
    "    8      2.360563   2.503586   -1.56986  \n",
    "    9      2.195155   2.530699   -1.578414 \n",
    "    10     2.133679   2.543678   -1.582569 \n",
    "    11     2.030446   2.514859   -1.571628 \n",
    "    12     1.786203   2.572578   -1.589976 \n",
    "    13     1.672956   2.588172   -1.59464  \n",
    "    14     1.49883    2.61061    -1.60179  \n",
    "    15     1.336165   2.697678   -1.628121 \n",
    "    16     1.202325   2.69454    -1.627483 \n",
    "    17     1.142886   2.745065   -1.642645 \n",
    "    18     0.926531   2.749832   -1.64373  \n",
    "    19     0.963009   2.737791   -1.639978 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192x4096neurons_100feats_0.01dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.051251   4.10799    -2.009398 \n",
    "    1      3.018563   3.528339   -1.862393 \n",
    "    2      2.83375    2.705865   -1.634455 \n",
    "    3      2.517056   3.031994   -1.726471 \n",
    "    4      2.494928   2.601024   -1.599418 \n",
    "    5      2.503645   2.540216   -1.582027 \n",
    "    6      2.353293   2.492889   -1.567174 \n",
    "    7      2.433681   2.601393   -1.600992 \n",
    "    8      2.52793    2.51109    -1.571607 \n",
    "    9      2.22963    2.507748   -1.570694 \n",
    "    10     2.027495   2.68182    -1.624424 \n",
    "    11     1.95731    2.544503   -1.581428 \n",
    "    12     1.815004   2.650318   -1.614484 \n",
    "    13     1.728487   2.630625   -1.60758  \n",
    "    14     1.582675   2.680908   -1.623436 \n",
    "    15     1.476325   2.693104   -1.626203 \n",
    "    16     1.362097   2.814843   -1.663315 \n",
    "    17     1.28207    2.790973   -1.656282 \n",
    "    18     1.259516   2.770683   -1.649667 \n",
    "    19     1.192445   2.781689   -1.65325  \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192x4096neurons_250feats_0.01dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.990759   4.108648   -2.009548 \n",
    "    1      3.984184   4.108211   -2.009439 \n",
    "    2      4.001595   4.108514   -2.009511 \n",
    "    3      3.875264   4.108514   -2.009511 \n",
    "    4      4.125242   4.108514   -2.009511 \n",
    "    5      4.297351   4.108514   -2.009511 \n",
    "    6      3.981093   4.108514   -2.009511 \n",
    "    7      4.140072   4.108513   -2.009511 \n",
    "    8      3.940661   4.10851    -2.00951  \n",
    "    9      3.888718   4.108517   -2.009512 \n",
    "    10     3.938608   4.108517   -2.009512 \n",
    "    11     3.812787   4.108517   -2.009512 \n",
    "    12     4.324084   4.108517   -2.009512 \n",
    "    13     3.980255   4.108517   -2.009512 \n",
    "    14     3.981436   4.108517   -2.009512 \n",
    "    15     4.008183   4.108517   -2.009512 \n",
    "    16     4.212946   4.108517   -2.009512 \n",
    "    17     4.121566   4.108517   -2.009512 \n",
    "    18     3.87319    4.108517   -2.009512 \n",
    "    19     4.072066   4.108517   -2.009512 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192x4096neurons_500feats_0.01dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.814378   4.108628   -2.009542 \n",
    "    1      3.972905   4.108584   -2.009531 \n",
    "    2      3.934108   4.108507   -2.009511 \n",
    "    3      4.384989   4.108193   -2.009435 \n",
    "    4      4.005821   4.108518   -2.009512 \n",
    "    5      4.204428   4.108517   -2.009512 \n",
    "    6      3.655825   4.108517   -2.009512 \n",
    "    7      4.028902   4.108517   -2.009512 \n",
    "    8      4.144756   4.108516   -2.009512 \n",
    "    9      3.941151   4.108515   -2.009511 \n",
    "    10     3.972211   4.108514   -2.009511 \n",
    "    11     3.910737   4.108516   -2.009512 \n",
    "    12     4.098143   4.108516   -2.009512 \n",
    "    13     4.102729   4.108516   -2.009512 \n",
    "    14     3.95018    4.108516   -2.009512 \n",
    "    15     4.084678   4.108516   -2.009512 \n",
    "    16     4.143422   4.108516   -2.009512 \n",
    "    17     4.014541   4.108514   -2.009511 \n",
    "    18     3.883301   3.982416   -1.97811  \n",
    "    19     2.909009   2.940852   -1.700725 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192x4096neurons_731feats_0.01dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.267223   4.108498   -2.009508 \n",
    "    1      4.292445   4.10848    -2.009504 \n",
    "    2      3.786921   4.108413   -2.009488 \n",
    "    3      3.987747   4.10847    -2.009501 \n",
    "    4      4.040804   4.108486   -2.009504 \n",
    "    5      4.048854   4.108517   -2.009512 \n",
    "    6      3.665128   4.108517   -2.009512 \n",
    "    7      3.868276   4.108517   -2.009512 \n",
    "    8      3.694925   4.108517   -2.009512 \n",
    "    9      3.968122   4.108517   -2.009512 \n",
    "    10     3.979161   4.108517   -2.009512 \n",
    "    11     4.049274   4.108517   -2.009512 \n",
    "    12     4.200727   4.108517   -2.009512 \n",
    "    13     4.228636   4.108517   -2.009512 \n",
    "    14     4.01711    4.108517   -2.009512 \n",
    "    15     3.999492   4.108517   -2.009512 \n",
    "    16     3.80302    4.108517   -2.009512 \n",
    "    17     4.310943   4.108517   -2.009512 \n",
    "    18     4.032498   4.108517   -2.009512 \n",
    "    19     4.214691   4.108517   -2.009512 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_2048neurons_100feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.465059   3.552266   -1.875248 \n",
    "    1      2.741765   2.859502   -1.67944  \n",
    "    2      2.587801   2.661189   -1.61985  \n",
    "    3      2.628445   2.591352   -1.598142 \n",
    "    4      2.375664   2.573003   -1.591875 \n",
    "    5      2.478393   2.528686   -1.578964 \n",
    "    6      2.556879   2.524343   -1.577194 \n",
    "    7      2.472191   2.520205   -1.575569 \n",
    "    8      2.186823   2.527389   -1.577303 \n",
    "    9      2.346387   2.522724   -1.576618 \n",
    "    10     2.288065   2.515154   -1.573771 \n",
    "    11     2.207133   2.587432   -1.597181 \n",
    "    12     2.203357   2.544041   -1.583106 \n",
    "    13     2.191185   2.53777    -1.581243 \n",
    "    14     2.156572   2.528643   -1.578012 \n",
    "    15     2.148023   2.536719   -1.580678 \n",
    "    16     2.039723   2.536067   -1.580668 \n",
    "    17     2.067877   2.5329     -1.579533 \n",
    "    18     1.956443   2.53134    -1.578912 \n",
    "    19     1.985858   2.537507   -1.581098 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_2048neurons_250feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.003444   3.691255   -1.912015 \n",
    "    1      2.886486   2.888707   -1.687749 \n",
    "    2      2.715677   2.716055   -1.635854 \n",
    "    3      2.682045   2.613284   -1.604417 \n",
    "    4      2.61701    2.563523   -1.588654 \n",
    "    5      2.586237   2.560077   -1.589097 \n",
    "    6      2.564508   2.511129   -1.572604 \n",
    "    7      2.322066   2.659457   -1.617178 \n",
    "    8      2.462194   2.50752    -1.571671 \n",
    "    9      2.490878   2.510861   -1.572214 \n",
    "    10     2.311045   2.510958   -1.572562 \n",
    "    11     2.303097   2.609657   -1.603882 \n",
    "    12     2.184123   2.491306   -1.565916 \n",
    "    13     2.212748   2.555293   -1.586406 \n",
    "    14     2.179615   2.527317   -1.577074 \n",
    "    15     2.016277   2.50041    -1.568804 \n",
    "    16     1.987339   2.496914   -1.568068 \n",
    "    17     2.029431   2.50749    -1.571306 \n",
    "    18     1.979293   2.500045   -1.568784 \n",
    "    19     2.048359   2.503079   -1.569804 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_2048neurons_500feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.447231   3.297504   -1.804902 \n",
    "    1      2.831342   2.886711   -1.685928 \n",
    "    2      2.698141   2.676196   -1.62324  \n",
    "    3      2.732269   2.669552   -1.620838 \n",
    "    4      2.550409   2.563543   -1.588173 \n",
    "    5      2.612654   2.574423   -1.590914 \n",
    "    6      2.322385   2.59981    -1.598516 \n",
    "    7      2.540854   2.552648   -1.585039 \n",
    "    8      2.510181   2.664959   -1.618301 \n",
    "    9      2.319921   2.524916   -1.57587  \n",
    "    10     2.288413   2.503707   -1.56939  \n",
    "    11     2.125504   2.49165    -1.56527  \n",
    "    12     2.101343   2.489078   -1.564728 \n",
    "    13     2.093841   2.498862   -1.568511 \n",
    "    14     2.005756   2.551634   -1.584848 \n",
    "    15     2.107815   2.526542   -1.576861 \n",
    "    16     1.863754   2.497999   -1.567629 \n",
    "    17     1.94803    2.498986   -1.568214 \n",
    "    18     1.794409   2.497153   -1.567365 \n",
    "    19     1.81973    2.499089   -1.56803  \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_2048neurons_731feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.637389   3.313478   -1.809345 \n",
    "    1      2.805467   2.878308   -1.684228 \n",
    "    2      2.83387    2.69233    -1.628935 \n",
    "    3      2.718342   2.717724   -1.635214 \n",
    "    4      2.769107   2.626166   -1.607672 \n",
    "    5      2.490994   2.578601   -1.593263 \n",
    "    6      2.510912   2.587532   -1.595498 \n",
    "    7      2.58583    2.557139   -1.586904 \n",
    "    8      2.495988   2.599752   -1.599384 \n",
    "    9      2.411984   2.546363   -1.58368  \n",
    "    10     2.304213   2.555486   -1.586315 \n",
    "    11     2.053042   2.528371   -1.57722  \n",
    "    12     2.106137   2.558567   -1.587365 \n",
    "    13     2.065857   2.493357   -1.566148 \n",
    "    14     1.955158   2.524229   -1.575063 \n",
    "    15     2.091402   2.503286   -1.569574 \n",
    "    16     1.951837   2.505273   -1.569791 \n",
    "    17     1.919136   2.504467   -1.569482 \n",
    "    18     1.803903   2.507831   -1.570824 \n",
    "    19     1.727971   2.504105   -1.569773 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192neurons_100feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.146632   3.139449   -1.760885 \n",
    "    1      2.839205   2.744453   -1.644866 \n",
    "    2      2.64689    2.634911   -1.611357 \n",
    "    3      2.546249   2.5936     -1.598966 \n",
    "    4      2.441295   2.616784   -1.606637 \n",
    "    5      2.595014   2.559993   -1.587882 \n",
    "    6      2.454097   2.595498   -1.598408 \n",
    "    7      2.462746   2.569924   -1.590899 \n",
    "    8      2.331697   2.67389    -1.62263  \n",
    "    9      2.316908   2.571416   -1.59062  \n",
    "    10     2.303219   2.758993   -1.649426 \n",
    "    11     2.374933   2.5904     -1.597457 \n",
    "    12     2.027281   2.635172   -1.610785 \n",
    "    13     2.09508    2.604357   -1.601154 \n",
    "    14     2.243915   2.598048   -1.599392 \n",
    "    15     2.038364   2.589902   -1.596936 \n",
    "    16     2.001162   2.593519   -1.597653 \n",
    "    17     1.912201   2.598582   -1.599585 \n",
    "    18     1.871863   2.58741    -1.595701 \n",
    "    19     1.871546   2.595522   -1.598347 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192neurons_250feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.9035     3.012946   -1.724013 \n",
    "    1      2.881845   2.703598   -1.632029 \n",
    "    2      2.864      2.689352   -1.627714 \n",
    "    3      2.791223   2.610648   -1.604439 \n",
    "    4      2.721052   2.566434   -1.590143 \n",
    "    5      2.626115   2.879697   -1.68257  \n",
    "    6      2.522445   2.613986   -1.604466 \n",
    "    7      2.498034   2.781747   -1.655646 \n",
    "    8      2.563938   2.682578   -1.623355 \n",
    "    9      2.40072    2.594073   -1.598041 \n",
    "    10     2.17095    2.546204   -1.582857 \n",
    "    11     2.260783   2.545735   -1.583693 \n",
    "    12     2.13334    2.565729   -1.589272 \n",
    "    13     2.147721   2.631713   -1.608704 \n",
    "    14     1.872782   2.588623   -1.596723 \n",
    "    15     1.924885   2.604693   -1.601474 \n",
    "    16     1.982318   2.564013   -1.589082 \n",
    "    17     1.869199   2.543351   -1.582308 \n",
    "    18     1.853399   2.532756   -1.579333 \n",
    "    19     1.76988    2.535813   -1.580309 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192neurons_500feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.941936   2.92169    -1.696879 \n",
    "    1      2.757056   2.732277   -1.640197 \n",
    "    2      2.846065   2.684766   -1.625298 \n",
    "    3      2.676574   2.908343   -1.691715 \n",
    "    4      2.682395   2.82951    -1.667475 \n",
    "    5      2.782655   2.71255    -1.63288  \n",
    "    6      2.579602   2.660172   -1.617478 \n",
    "    7      3.004463   2.935498   -1.698734 \n",
    "    8      2.489039   2.723288   -1.637146 \n",
    "    9      2.337461   2.607465   -1.600837 \n",
    "    10     2.323829   2.755797   -1.645572 \n",
    "    11     2.252554   2.534657   -1.578903 \n",
    "    12     2.131869   2.655812   -1.616249 \n",
    "    13     2.012807   2.593004   -1.596763 \n",
    "    14     2.053942   2.683457   -1.62539  \n",
    "    15     1.936584   2.637744   -1.611422 \n",
    "    16     1.76976    2.555749   -1.586011 \n",
    "    17     1.685537   2.562999   -1.588207 \n",
    "    18     1.662425   2.589955   -1.596158 \n",
    "    19     1.696042   2.552521   -1.584894 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192neurons_731feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.922956   2.896902   -1.688998 \n",
    "    1      2.842893   2.733645   -1.639918 \n",
    "    2      2.771925   2.654775   -1.61543  \n",
    "    3      2.501476   2.646379   -1.61334  \n",
    "    4      2.652112   2.668309   -1.619033 \n",
    "    5      2.75028    2.653675   -1.615483 \n",
    "    6      2.673646   2.731636   -1.637963 \n",
    "    7      2.488436   2.84908    -1.672388 \n",
    "    8      2.39162    2.659905   -1.616408 \n",
    "    9      2.389776   2.632234   -1.60791  \n",
    "    10     2.316386   2.601165   -1.598896 \n",
    "    11     2.119191   2.602972   -1.598898 \n",
    "    12     2.151032   2.57206    -1.590703 \n",
    "    13     2.108949   2.707523   -1.631113 \n",
    "    14     1.936357   2.568524   -1.588753 \n",
    "    15     1.950848   2.613192   -1.603201 \n",
    "    16     1.771213   2.621796   -1.606172 \n",
    "    17     1.5993     2.573055   -1.590949 \n",
    "    18     1.595623   2.555119   -1.584812 \n",
    "    19     1.641239   2.577429   -1.592069 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_16384neurons_100feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.013157   2.993843   -1.719037 \n",
    "    1      2.817421   2.731929   -1.642054 \n",
    "    2      2.687612   2.607068   -1.603275 \n",
    "    3      2.564869   2.587205   -1.596127 \n",
    "    4      2.54781    2.561709   -1.588308 \n",
    "    5      2.491046   2.703646   -1.630897 \n",
    "    6      2.386324   3.227339   -1.78156  \n",
    "    7      2.502805   2.626064   -1.607813 \n",
    "    8      2.414318   2.580411   -1.593756 \n",
    "    9      2.601537   2.730181   -1.639917 \n",
    "    10     2.299748   2.761032   -1.647683 \n",
    "    11     2.207357   2.571969   -1.589847 \n",
    "    12     1.959239   2.587646   -1.595099 \n",
    "    13     2.10523    2.664843   -1.61904  \n",
    "    14     1.955635   2.588632   -1.596299 \n",
    "    15     1.766736   2.596962   -1.598521 \n",
    "    16     1.876739   2.607384   -1.602206 \n",
    "    17     1.819718   2.613181   -1.603653 \n",
    "    18     1.844544   2.592061   -1.59711  \n",
    "    19     1.726832   2.598042   -1.599018 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_16384neurons_250feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      2.77713    2.845059   -1.674967 \n",
    "    1      2.733036   2.667822   -1.620639 \n",
    "    2      2.674186   2.710482   -1.632878 \n",
    "    3      2.637989   2.598208   -1.599157 \n",
    "    4      2.607997   2.645572   -1.613175 \n",
    "    5      2.509053   2.656356   -1.615282 \n",
    "    6      2.667914   2.9244     -1.695073 \n",
    "    7      2.560045   2.84786    -1.672607 \n",
    "    8      2.588362   2.631139   -1.609051 \n",
    "    9      2.274589   2.627134   -1.606677 \n",
    "    10     2.250484   2.748767   -1.642424 \n",
    "    11     2.266772   2.612838   -1.602769 \n",
    "    12     2.125935   2.634646   -1.610168 \n",
    "    13     1.928134   2.575074   -1.59161  \n",
    "    14     1.901503   2.578965   -1.592987 \n",
    "    15     2.010812   2.573627   -1.591104 \n",
    "    16     1.897857   2.542696   -1.581627 \n",
    "    17     1.704006   2.598848   -1.599385 \n",
    "    18     1.659012   2.593227   -1.597545 \n",
    "    19     1.593815   2.5594     -1.587048 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_16384neurons_500feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.050581   2.892857   -1.688439 \n",
    "    1      3.15367    2.732953   -1.639993 \n",
    "    2      2.717062   2.648263   -1.614375 \n",
    "    3      2.75079    2.653721   -1.615096 \n",
    "    4      2.483266   2.841368   -1.670399 \n",
    "    5      2.734152   2.693889   -1.627193 \n",
    "    6      2.724538   2.802753   -1.660872 \n",
    "    7      2.948558   2.903374   -1.688845 \n",
    "    8      2.665206   2.746483   -1.642968 \n",
    "    9      2.472847   2.771311   -1.65068  \n",
    "    10     2.144331   2.69438    -1.626986 \n",
    "    11     2.092531   3.358756   -1.817441 \n",
    "    12     2.178762   2.704106   -1.630775 \n",
    "    13     2.149505   2.635823   -1.610878 \n",
    "    14     1.876237   2.688184   -1.626918 \n",
    "    15     1.912312   2.582734   -1.59395  \n",
    "    16     1.743971   2.596927   -1.598195 \n",
    "    17     1.668022   2.580569   -1.593155 \n",
    "    18     1.607788   2.584672   -1.594485 \n",
    "    19     1.599607   2.60157    -1.599984 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_16384neurons_731feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.05505    2.929543   -1.698155 \n",
    "    1      2.77757    2.984527   -1.712175 \n",
    "    2      2.808058   2.874508   -1.680118 \n",
    "    3      2.789674   2.69863    -1.628284 \n",
    "    4      3.16601    3.681599   -1.902655 \n",
    "    5      2.932244   2.845527   -1.670359 \n",
    "    6      2.87004    2.823889   -1.662565 \n",
    "    7      2.806794   2.846384   -1.671803 \n",
    "    8      2.926634   2.767522   -1.648544 \n",
    "    9      2.642209   2.786976   -1.654598 \n",
    "    10     2.380043   2.637003   -1.609764 \n",
    "    11     2.235979   2.692753   -1.627437 \n",
    "    12     2.270823   2.750267   -1.645144 \n",
    "    13     2.193501   2.667392   -1.619904 \n",
    "    14     1.937485   2.638942   -1.61084  \n",
    "    15     1.83135    2.623403   -1.606217 \n",
    "    16     1.691076   2.734297   -1.640294 \n",
    "    17     1.626486   2.602906   -1.599705 \n",
    "    18     1.557559   2.593452   -1.596531 \n",
    "    19     1.585719   2.603647   -1.600027 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_100feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.280624   4.112193   -2.010502 \n",
    "    1      3.074467   2.890885   -1.688394 \n",
    "    2      2.750293   2.616987   -1.607565 \n",
    "    3      2.776349   2.566715   -1.590213 \n",
    "    4      2.805554   2.610063   -1.60451  \n",
    "    5      2.437404   2.555022   -1.586554 \n",
    "    6      2.357925   2.531625   -1.57828  \n",
    "    7      2.517236   2.509669   -1.57291  \n",
    "    8      2.385722   2.539844   -1.581238 \n",
    "    9      2.321683   2.477158   -1.561532 \n",
    "    10     2.368044   2.49578    -1.567191 \n",
    "    11     2.13621    2.527366   -1.577093 \n",
    "    12     2.138045   2.558824   -1.585832 \n",
    "    13     1.966953   2.586059   -1.594426 \n",
    "    14     1.81355    2.551488   -1.58322  \n",
    "    15     1.959536   2.648395   -1.614596 \n",
    "    16     1.746391   2.591004   -1.595468 \n",
    "    17     1.685833   2.592836   -1.596247 \n",
    "    18     1.752111   2.588243   -1.594474 \n",
    "    19     1.660288   2.612085   -1.602023 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_250feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.169043   4.113401   -2.010842 \n",
    "    1      3.046911   2.878612   -1.683002 \n",
    "    2      2.770045   2.741901   -1.643842 \n",
    "    3      2.773397   2.568246   -1.591095 \n",
    "    4      2.740054   2.559991   -1.586918 \n",
    "    5      2.514635   2.670502   -1.621785 \n",
    "    6      2.486339   2.653746   -1.615238 \n",
    "    7      2.412525   2.591663   -1.597512 \n",
    "    8      2.599979   2.572776   -1.593074 \n",
    "    9      2.136695   2.452604   -1.553861 \n",
    "    10     2.121202   2.482462   -1.563232 \n",
    "    11     2.22624    2.446884   -1.552525 \n",
    "    12     2.05582    2.534001   -1.579589 \n",
    "    13     1.937695   2.609576   -1.603558 \n",
    "    14     1.968256   2.519932   -1.574255 \n",
    "    15     1.769781   2.607157   -1.601755 \n",
    "    16     1.617191   2.546997   -1.582234 \n",
    "    17     1.610582   2.61933    -1.60488  \n",
    "    18     1.354762   2.5918     -1.596212 \n",
    "    19     1.529911   2.605615   -1.600541 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_500feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.799617   4.109846   -2.009942 \n",
    "    1      2.818606   2.826132   -1.667525 \n",
    "    2      2.851445   2.779082   -1.654678 \n",
    "    3      2.951059   2.770843   -1.651006 \n",
    "    4      2.508049   2.609799   -1.603375 \n",
    "    5      2.601054   2.599303   -1.601662 \n",
    "    6      2.562373   2.550932   -1.585304 \n",
    "    7      2.453752   2.495261   -1.568067 \n",
    "    8      2.455731   2.57101    -1.589363 \n",
    "    9      2.381001   2.478902   -1.562193 \n",
    "    10     2.200803   2.522478   -1.575003 \n",
    "    11     2.127516   2.505811   -1.570998 \n",
    "    12     1.966195   2.521955   -1.575389 \n",
    "    13     1.953774   2.550644   -1.584141 \n",
    "    14     1.836536   2.604799   -1.601123 \n",
    "    15     1.697073   2.707386   -1.632473 \n",
    "    16     1.564976   2.633472   -1.609542 \n",
    "    17     1.563312   2.642268   -1.612149 \n",
    "    18     1.451467   2.658444   -1.616747 \n",
    "    19     1.411612   2.666087   -1.619109 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_4096x2048neurons_731feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.337063   4.108493   -2.009589 \n",
    "    1      2.983268   3.105068   -1.748116 \n",
    "    2      2.863731   2.85768    -1.675596 \n",
    "    3      2.646746   2.613936   -1.603386 \n",
    "    4      2.584274   2.597283   -1.59938  \n",
    "    5      2.563538   2.517856   -1.574501 \n",
    "    6      2.467589   2.627722   -1.607634 \n",
    "    7      2.331647   2.535659   -1.580743 \n",
    "    8      2.314513   2.494409   -1.566808 \n",
    "    9      2.268411   2.506171   -1.569498 \n",
    "    10     2.243475   2.535924   -1.580582 \n",
    "    11     2.208516   2.580859   -1.594339 \n",
    "    12     1.940213   2.489978   -1.56386  \n",
    "    13     2.012977   2.514095   -1.572586 \n",
    "    14     1.900019   2.583684   -1.593992 \n",
    "    15     1.674733   2.602015   -1.599547 \n",
    "    16     1.487916   2.612445   -1.602235 \n",
    "    17     1.45869    2.598534   -1.597523 \n",
    "    18     1.547392   2.622391   -1.604777 \n",
    "    19     1.384717   2.648419   -1.613128 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192x4096neurons_100feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.14163    4.110584   -2.010064 \n",
    "    1      3.81156    4.045967   -1.994224 \n",
    "    2      2.775196   2.789592   -1.656299 \n",
    "    3      2.607651   2.576598   -1.593047 \n",
    "    4      2.420194   2.531235   -1.579877 \n",
    "    5      2.572757   2.518684   -1.575636 \n",
    "    6      2.34277    2.515348   -1.572656 \n",
    "    7      2.379807   2.569668   -1.590358 \n",
    "    8      2.286511   2.525051   -1.575593 \n",
    "    9      2.270486   2.499648   -1.568084 \n",
    "    10     2.091094   2.5847     -1.595572 \n",
    "    11     1.990909   2.572511   -1.591092 \n",
    "    12     2.015035   2.557729   -1.586136 \n",
    "    13     1.802545   2.643177   -1.61305  \n",
    "    14     1.717645   2.63159    -1.608123 \n",
    "    15     1.669647   2.635368   -1.609448 \n",
    "    16     1.540648   2.653998   -1.614667 \n",
    "    17     1.466819   2.665495   -1.618002 \n",
    "    18     1.485802   2.723572   -1.635916 \n",
    "    19     1.449646   2.71857    -1.634403 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192x4096neurons_250feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.038392   4.108944   -2.009625 \n",
    "    1      3.801897   4.108507   -2.009515 \n",
    "    2      4.001073   4.106823   -2.009103 \n",
    "    3      4.077693   4.108242   -2.009444 \n",
    "    4      3.63653    4.108497   -2.009507 \n",
    "    5      4.042833   4.108491   -2.009505 \n",
    "    6      3.940178   4.108438   -2.009492 \n",
    "    7      3.862192   4.108516   -2.009512 \n",
    "    8      3.968679   4.108515   -2.009511 \n",
    "    9      3.897806   4.108514   -2.009511 \n",
    "    10     4.077841   4.108517   -2.009512 \n",
    "    11     4.384231   4.108517   -2.009512 \n",
    "    12     3.954978   4.108517   -2.009512 \n",
    "    13     4.006875   4.108517   -2.009512 \n",
    "    14     3.788576   4.108517   -2.009512 \n",
    "    15     4.053283   4.108517   -2.009512 \n",
    "    16     4.034974   4.108517   -2.009512 \n",
    "    17     4.018452   4.108517   -2.009512 \n",
    "    18     3.994536   4.108517   -2.009512 \n",
    "    19     4.119493   4.108517   -2.009512 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192x4096neurons_500feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.990755   4.108549   -2.009522 \n",
    "    1      3.763958   4.10849    -2.009507 \n",
    "    2      4.101643   4.108213   -2.00944  \n",
    "    3      4.153758   4.108518   -2.009512 \n",
    "    4      4.012665   4.108517   -2.009512 \n",
    "    5      3.947013   4.108516   -2.009512 \n",
    "    6      4.25497    4.108515   -2.009511 \n",
    "    7      3.813813   4.108514   -2.009511 \n",
    "    8      4.247601   4.108507   -2.009509 \n",
    "    9      4.110991   4.108516   -2.009512 \n",
    "    10     4.493663   4.108516   -2.009512 \n",
    "    11     3.994792   4.108516   -2.009512 \n",
    "    12     3.879443   4.108516   -2.009512 \n",
    "    13     4.227847   4.108516   -2.009512 \n",
    "    14     3.938068   4.108511   -2.00951  \n",
    "    15     4.097453   4.108516   -2.009512 \n",
    "    16     4.118954   4.108516   -2.009512 \n",
    "    17     4.23578    4.108516   -2.009512 \n",
    "    18     3.940719   4.087444   -2.004272 \n",
    "    19     3.995493   4.079875   -2.00238  \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_8192x4096neurons_731feats_0.15dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      4.243833   4.108473   -2.009502 \n",
    "    1      3.928415   4.10845    -2.009497 \n",
    "    2      4.015295   4.108335   -2.009469 \n",
    "    3      4.038502   4.1085     -2.009508 \n",
    "    4      4.104034   4.10847    -2.009501 \n",
    "    5      4.068937   4.108517   -2.009512 \n",
    "    6      3.954951   4.108517   -2.009512 \n",
    "    7      4.007005   4.108517   -2.009512 \n",
    "    8      4.165347   4.108517   -2.009512 \n",
    "    9      3.929082   4.108517   -2.009512 \n",
    "    10     4.147555   4.108517   -2.009512 \n",
    "    11     3.822009   4.108517   -2.009512 \n",
    "    12     3.734146   4.108517   -2.009512 \n",
    "    13     4.226884   4.108517   -2.009512 \n",
    "    14     3.801415   4.108517   -2.009512 \n",
    "    15     4.034234   4.108517   -2.009512 \n",
    "    16     4.075243   4.108517   -2.009512 \n",
    "    17     4.050493   4.108517   -2.009512 \n",
    "    18     4.120514   4.108517   -2.009512 \n",
    "    19     3.970693   4.108517   -2.009512 \n",
    "\n",
    "\n",
    "\n",
    "Starting: fm&p_1cycle_flgs_2048neurons_100feats_0.3dropout_20cl_10lrr_2018-10-17-17-24-40 \n",
    "\n",
    "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))\n",
    "epoch      trn_loss   val_loss   neg_rmse   \n",
    "    0      3.363709   3.395956   -1.832996 \n",
    "    1      2.831663   2.811741   -1.664886 \n",
    "    2      2.650207   2.636163   -1.612297 \n",
    "    3      2.465691   2.567301   -1.590774 \n",
    "    4      2.57741    2.524277   -1.57719  \n",
    "    5      2.447885   2.507713   -1.572158 \n",
    "    6      2.487683   2.540072   -1.582518 \n",
    "    7      2.388579   2.523093   -1.575696 \n",
    "    8      2.478093   2.506837   -1.571314 \n",
    "    9      2.448776   2.529975   -1.578615 \n",
    "    10     2.312754   2.570543   -1.591397 \n",
    "    11     2.193284   2.556333   -1.586508 \n",
    "    12     2.247633   2.52998    -1.578544 \n",
    "    13     2.105355   2.5282     -1.577487 \n",
    "    14     2.073181   2.523694   -1.576267 \n",
    "    15     2.070197   2.558186   -1.587828 \n",
    "    16     2.157525   2.550647   -1.585226 \n",
    "    17     2.063111   2.540342   -1.581607 \n",
    "    18     1.988707   2.547217   -1.583794 \n",
    "    19     2.086729   2.546725   -1.583657 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_get_val_loss(df, df_test, saved_weights, loc_val_idx):\n",
    "    \n",
    "    # set data based on feature importance\n",
    "    use_features = deepcopy(get_features(int(saved_weights.split('_')[4].replace('feats',''))))\n",
    "    df = deepcopy(df[use_features])\n",
    "    df_test = deepcopy(df_test[use_features])\n",
    "    \n",
    "    # init model objects\n",
    "    md = ColumnarModelData.from_data_frame(path = 'models', val_idxs = loc_val_idx, df = df,\n",
    "                                          y = yl.astype(np.float32), cat_flds = cat_vars,\n",
    "                                          bs = 512, test_df = df_test)\n",
    "    \n",
    "    # set params\n",
    "    arch_str = saved_weights.split('_')[3].replace('neurons','')\n",
    "    if 'x' in arch_str:\n",
    "        arch = [int(x) for x in arch_str.split('x')]\n",
    "    else:\n",
    "        arch = [int(arch_str)]\n",
    "    dropout = [float(saved_weights.split('_')[5].replace('dropout','')) for _ in range(len(arch))]\n",
    "    \n",
    "    # init model\n",
    "    m = md.get_learner(emb_szs = emb_szs, n_cont = len(df.columns) - len(cat_vars),\n",
    "                       emb_drop = 0.04, out_sz = 1, szs = arch, drops = dropout, y_range = y_range)\n",
    "    \n",
    "    # load saved weights\n",
    "    m.load(saved_weights)\n",
    "    \n",
    "    # calc rmse\n",
    "    yl_val = deepcopy(yl[loc_val_idx])\n",
    "    yl_hat = deepcopy(m.predict().reshape(-1,))\n",
    "    error = abs(neg_rmse(yl_hat, yl_val))\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_loss = {}\n",
    "for w in already_done:\n",
    "    \n",
    "    print('starting:', w)\n",
    "    \n",
    "    # get validation idxs\n",
    "    val_idx_filename = 'val_idx_saves/validation_idxs_{}.pkl'.format(w.split('_')[-1])\n",
    "    with open(val_idx_filename, \"rb\") as input_file:\n",
    "        testing_val_idx = pickle.load(input_file)\n",
    "    \n",
    "    overall_loss[w] = load_model_get_val_loss(df = df, df_test = df_test,\n",
    "                                              saved_weights = w, loc_val_idx = testing_val_idx)\n",
    "\n",
    "# parse performance\n",
    "model_performace = pd.DataFrame([deepcopy({'model': k, 'loss': v}) for k, v in overall_loss.items()])\n",
    "model_performace['neurons'] = model_performace['model'].apply(lambda x: x.split('_')[3].replace('neurons',''))\n",
    "model_performace['features'] = model_performace['model'].apply(lambda x: x.split('_')[4].replace('feats',''))\n",
    "model_performace['dropout'] = model_performace['model'].apply(lambda x: x.split('_')[5].replace('dropout',''))\n",
    "model_performace['cycle_len'] = model_performace['model'].apply(lambda x: x.split('_')[6].replace('cl',''))\n",
    "model_performace['lrr'] = model_performace['model'].apply(lambda x: x.split('_')[7].replace('lrr',''))\n",
    "model_performace['loss'] = deepcopy(abs(model_performace['loss']))\n",
    "model_performance = deepcopy(model_performace.sort_values('loss').reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_performance.to_csv('feature_gs_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neurons</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8192</th>\n",
       "      <td>1.994703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8192x4096</th>\n",
       "      <td>2.007023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>2.013367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16384</th>\n",
       "      <td>2.036763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4096x2048</th>\n",
       "      <td>2.113533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               loss\n",
       "neurons            \n",
       "8192       1.994703\n",
       "8192x4096  2.007023\n",
       "2048       2.013367\n",
       "16384      2.036763\n",
       "4096x2048  2.113533"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance.groupby('neurons').mean().sort_values('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results & Training Note on `metric` & `best_save_name`\n",
    "\n",
    "There is clearly something very wrong with the `best_save_name` callback when using a custom metric. I've tried using a metric to both minimize and maximize but it doesn't seem to work with how it's currently set up. For the future, it is advised to run a short QA to see if the metric is being calculated correctly and the results are as expected, and then **complete all further training and optimization without using a custom metric**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>model</th>\n",
       "      <th>neurons</th>\n",
       "      <th>features</th>\n",
       "      <th>dropout</th>\n",
       "      <th>cycle_len</th>\n",
       "      <th>lrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.768103</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_8192neurons_100feats_0.45drop...</td>\n",
       "      <td>8192</td>\n",
       "      <td>100</td>\n",
       "      <td>0.45</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.769896</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_100feats_0.15drop...</td>\n",
       "      <td>2048</td>\n",
       "      <td>100</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.777401</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_100feats_0.45drop...</td>\n",
       "      <td>2048</td>\n",
       "      <td>100</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.787452</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_100feats_0.3dropo...</td>\n",
       "      <td>2048</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.788734</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_8192neurons_100feats_0.15drop...</td>\n",
       "      <td>8192</td>\n",
       "      <td>100</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.797968</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_16384neurons_100feats_0.15dro...</td>\n",
       "      <td>16384</td>\n",
       "      <td>100</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.798603</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_8192neurons_250feats_0.3dropo...</td>\n",
       "      <td>8192</td>\n",
       "      <td>250</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.804796</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_100feats_0.01drop...</td>\n",
       "      <td>2048</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.806038</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_100feats_0.3dropo...</td>\n",
       "      <td>2048</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.812006</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_8192x4096neurons_100feats_0.3...</td>\n",
       "      <td>8192x4096</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.813452</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_8192neurons_100feats_0.15drop...</td>\n",
       "      <td>8192</td>\n",
       "      <td>100</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.814325</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_4096x2048neurons_100feats_0.0...</td>\n",
       "      <td>4096x2048</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.832822</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_8192neurons_100feats_0.45drop...</td>\n",
       "      <td>8192</td>\n",
       "      <td>100</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.833908</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_100feats_0.01drop...</td>\n",
       "      <td>2048</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.837309</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_8192neurons_100feats_0.3dropo...</td>\n",
       "      <td>8192</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.837630</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_4096x2048neurons_100feats_0.3...</td>\n",
       "      <td>4096x2048</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.847583</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_100feats_0.15drop...</td>\n",
       "      <td>2048</td>\n",
       "      <td>100</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.848244</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_8192neurons_100feats_0.01drop...</td>\n",
       "      <td>8192</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.861519</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_16384neurons_100feats_0.3drop...</td>\n",
       "      <td>16384</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.868653</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_16384neurons_100feats_0.15dro...</td>\n",
       "      <td>16384</td>\n",
       "      <td>100</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.871804</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_4096x2048neurons_100feats_0.4...</td>\n",
       "      <td>4096x2048</td>\n",
       "      <td>100</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.877688</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_8192neurons_100feats_0.01drop...</td>\n",
       "      <td>8192</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.878120</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_8192neurons_250feats_0.45drop...</td>\n",
       "      <td>8192</td>\n",
       "      <td>250</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.884852</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_16384neurons_250feats_0.3drop...</td>\n",
       "      <td>16384</td>\n",
       "      <td>250</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.890693</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_100feats_0.45drop...</td>\n",
       "      <td>2048</td>\n",
       "      <td>100</td>\n",
       "      <td>0.45</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.893347</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_250feats_0.15drop...</td>\n",
       "      <td>2048</td>\n",
       "      <td>250</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.893674</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_250feats_0.3dropo...</td>\n",
       "      <td>2048</td>\n",
       "      <td>250</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.895603</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_16384neurons_100feats_0.01dro...</td>\n",
       "      <td>16384</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.898646</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_4096x2048neurons_100feats_0.1...</td>\n",
       "      <td>4096x2048</td>\n",
       "      <td>100</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.905404</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_16384neurons_100feats_0.3drop...</td>\n",
       "      <td>16384</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2.149316</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_8192neurons_731feats_0.15drop...</td>\n",
       "      <td>8192</td>\n",
       "      <td>731</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2.153480</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_4096x2048neurons_500feats_0.1...</td>\n",
       "      <td>4096x2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2.160872</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_500feats_0.15drop...</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2.175784</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_500feats_0.3dropo...</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2.184568</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_8192neurons_250feats_0.01drop...</td>\n",
       "      <td>8192</td>\n",
       "      <td>250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2.195689</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_4096x2048neurons_731feats_0.4...</td>\n",
       "      <td>4096x2048</td>\n",
       "      <td>731</td>\n",
       "      <td>0.45</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2.197345</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_731feats_0.45drop...</td>\n",
       "      <td>2048</td>\n",
       "      <td>731</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2.205033</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_4096x2048neurons_500feats_0.0...</td>\n",
       "      <td>4096x2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2.206717</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_16384neurons_731feats_0.15dro...</td>\n",
       "      <td>16384</td>\n",
       "      <td>731</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2.208158</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_731feats_0.01drop...</td>\n",
       "      <td>2048</td>\n",
       "      <td>731</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2.223637</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_731feats_0.15drop...</td>\n",
       "      <td>2048</td>\n",
       "      <td>731</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2.230129</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_4096x2048neurons_731feats_0.0...</td>\n",
       "      <td>4096x2048</td>\n",
       "      <td>731</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2.238528</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_4096x2048neurons_500feats_0.3...</td>\n",
       "      <td>4096x2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2.242946</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_8192neurons_500feats_0.01drop...</td>\n",
       "      <td>8192</td>\n",
       "      <td>500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2.261656</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_16384neurons_500feats_0.01dro...</td>\n",
       "      <td>16384</td>\n",
       "      <td>500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2.272089</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_731feats_0.01drop...</td>\n",
       "      <td>2048</td>\n",
       "      <td>731</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2.273559</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_500feats_0.01drop...</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2.285709</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_4096x2048neurons_500feats_0.4...</td>\n",
       "      <td>4096x2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2.286338</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_500feats_0.15drop...</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2.292979</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_4096x2048neurons_731feats_0.0...</td>\n",
       "      <td>4096x2048</td>\n",
       "      <td>731</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2.333473</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_4096x2048neurons_731feats_0.4...</td>\n",
       "      <td>4096x2048</td>\n",
       "      <td>731</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2.337282</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_4096x2048neurons_731feats_0.1...</td>\n",
       "      <td>4096x2048</td>\n",
       "      <td>731</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2.359264</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_4096x2048neurons_250feats_0.1...</td>\n",
       "      <td>4096x2048</td>\n",
       "      <td>250</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2.387409</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_4096x2048neurons_731feats_0.3...</td>\n",
       "      <td>4096x2048</td>\n",
       "      <td>731</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2.413591</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_2048neurons_731feats_0.3dropo...</td>\n",
       "      <td>2048</td>\n",
       "      <td>731</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2.458952</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_16384neurons_500feats_0.15dro...</td>\n",
       "      <td>16384</td>\n",
       "      <td>500</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2.459409</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_16384neurons_731feats_0.3drop...</td>\n",
       "      <td>16384</td>\n",
       "      <td>731</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2.467137</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_4096x2048neurons_731feats_0.3...</td>\n",
       "      <td>4096x2048</td>\n",
       "      <td>731</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2.488439</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_4096x2048neurons_731feats_0.1...</td>\n",
       "      <td>4096x2048</td>\n",
       "      <td>731</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2.742760</td>\n",
       "      <td>fm&amp;p_1cycle_flgs_8192neurons_731feats_0.45drop...</td>\n",
       "      <td>8192</td>\n",
       "      <td>731</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss                                              model    neurons  \\\n",
       "0    1.768103  fm&p_1cycle_flgs_8192neurons_100feats_0.45drop...       8192   \n",
       "1    1.769896  fm&p_1cycle_flgs_2048neurons_100feats_0.15drop...       2048   \n",
       "2    1.777401  fm&p_1cycle_flgs_2048neurons_100feats_0.45drop...       2048   \n",
       "3    1.787452  fm&p_1cycle_flgs_2048neurons_100feats_0.3dropo...       2048   \n",
       "4    1.788734  fm&p_1cycle_flgs_8192neurons_100feats_0.15drop...       8192   \n",
       "5    1.797968  fm&p_1cycle_flgs_16384neurons_100feats_0.15dro...      16384   \n",
       "6    1.798603  fm&p_1cycle_flgs_8192neurons_250feats_0.3dropo...       8192   \n",
       "7    1.804796  fm&p_1cycle_flgs_2048neurons_100feats_0.01drop...       2048   \n",
       "8    1.806038  fm&p_1cycle_flgs_2048neurons_100feats_0.3dropo...       2048   \n",
       "9    1.812006  fm&p_1cycle_flgs_8192x4096neurons_100feats_0.3...  8192x4096   \n",
       "10   1.813452  fm&p_1cycle_flgs_8192neurons_100feats_0.15drop...       8192   \n",
       "11   1.814325  fm&p_1cycle_flgs_4096x2048neurons_100feats_0.0...  4096x2048   \n",
       "12   1.832822  fm&p_1cycle_flgs_8192neurons_100feats_0.45drop...       8192   \n",
       "13   1.833908  fm&p_1cycle_flgs_2048neurons_100feats_0.01drop...       2048   \n",
       "14   1.837309  fm&p_1cycle_flgs_8192neurons_100feats_0.3dropo...       8192   \n",
       "15   1.837630  fm&p_1cycle_flgs_4096x2048neurons_100feats_0.3...  4096x2048   \n",
       "16   1.847583  fm&p_1cycle_flgs_2048neurons_100feats_0.15drop...       2048   \n",
       "17   1.848244  fm&p_1cycle_flgs_8192neurons_100feats_0.01drop...       8192   \n",
       "18   1.861519  fm&p_1cycle_flgs_16384neurons_100feats_0.3drop...      16384   \n",
       "19   1.868653  fm&p_1cycle_flgs_16384neurons_100feats_0.15dro...      16384   \n",
       "20   1.871804  fm&p_1cycle_flgs_4096x2048neurons_100feats_0.4...  4096x2048   \n",
       "21   1.877688  fm&p_1cycle_flgs_8192neurons_100feats_0.01drop...       8192   \n",
       "22   1.878120  fm&p_1cycle_flgs_8192neurons_250feats_0.45drop...       8192   \n",
       "23   1.884852  fm&p_1cycle_flgs_16384neurons_250feats_0.3drop...      16384   \n",
       "24   1.890693  fm&p_1cycle_flgs_2048neurons_100feats_0.45drop...       2048   \n",
       "25   1.893347  fm&p_1cycle_flgs_2048neurons_250feats_0.15drop...       2048   \n",
       "26   1.893674  fm&p_1cycle_flgs_2048neurons_250feats_0.3dropo...       2048   \n",
       "27   1.895603  fm&p_1cycle_flgs_16384neurons_100feats_0.01dro...      16384   \n",
       "28   1.898646  fm&p_1cycle_flgs_4096x2048neurons_100feats_0.1...  4096x2048   \n",
       "29   1.905404  fm&p_1cycle_flgs_16384neurons_100feats_0.3drop...      16384   \n",
       "..        ...                                                ...        ...   \n",
       "126  2.149316  fm&p_1cycle_flgs_8192neurons_731feats_0.15drop...       8192   \n",
       "127  2.153480  fm&p_1cycle_flgs_4096x2048neurons_500feats_0.1...  4096x2048   \n",
       "128  2.160872  fm&p_1cycle_flgs_2048neurons_500feats_0.15drop...       2048   \n",
       "129  2.175784  fm&p_1cycle_flgs_2048neurons_500feats_0.3dropo...       2048   \n",
       "130  2.184568  fm&p_1cycle_flgs_8192neurons_250feats_0.01drop...       8192   \n",
       "131  2.195689  fm&p_1cycle_flgs_4096x2048neurons_731feats_0.4...  4096x2048   \n",
       "132  2.197345  fm&p_1cycle_flgs_2048neurons_731feats_0.45drop...       2048   \n",
       "133  2.205033  fm&p_1cycle_flgs_4096x2048neurons_500feats_0.0...  4096x2048   \n",
       "134  2.206717  fm&p_1cycle_flgs_16384neurons_731feats_0.15dro...      16384   \n",
       "135  2.208158  fm&p_1cycle_flgs_2048neurons_731feats_0.01drop...       2048   \n",
       "136  2.223637  fm&p_1cycle_flgs_2048neurons_731feats_0.15drop...       2048   \n",
       "137  2.230129  fm&p_1cycle_flgs_4096x2048neurons_731feats_0.0...  4096x2048   \n",
       "138  2.238528  fm&p_1cycle_flgs_4096x2048neurons_500feats_0.3...  4096x2048   \n",
       "139  2.242946  fm&p_1cycle_flgs_8192neurons_500feats_0.01drop...       8192   \n",
       "140  2.261656  fm&p_1cycle_flgs_16384neurons_500feats_0.01dro...      16384   \n",
       "141  2.272089  fm&p_1cycle_flgs_2048neurons_731feats_0.01drop...       2048   \n",
       "142  2.273559  fm&p_1cycle_flgs_2048neurons_500feats_0.01drop...       2048   \n",
       "143  2.285709  fm&p_1cycle_flgs_4096x2048neurons_500feats_0.4...  4096x2048   \n",
       "144  2.286338  fm&p_1cycle_flgs_2048neurons_500feats_0.15drop...       2048   \n",
       "145  2.292979  fm&p_1cycle_flgs_4096x2048neurons_731feats_0.0...  4096x2048   \n",
       "146  2.333473  fm&p_1cycle_flgs_4096x2048neurons_731feats_0.4...  4096x2048   \n",
       "147  2.337282  fm&p_1cycle_flgs_4096x2048neurons_731feats_0.1...  4096x2048   \n",
       "148  2.359264  fm&p_1cycle_flgs_4096x2048neurons_250feats_0.1...  4096x2048   \n",
       "149  2.387409  fm&p_1cycle_flgs_4096x2048neurons_731feats_0.3...  4096x2048   \n",
       "150  2.413591  fm&p_1cycle_flgs_2048neurons_731feats_0.3dropo...       2048   \n",
       "151  2.458952  fm&p_1cycle_flgs_16384neurons_500feats_0.15dro...      16384   \n",
       "152  2.459409  fm&p_1cycle_flgs_16384neurons_731feats_0.3drop...      16384   \n",
       "153  2.467137  fm&p_1cycle_flgs_4096x2048neurons_731feats_0.3...  4096x2048   \n",
       "154  2.488439  fm&p_1cycle_flgs_4096x2048neurons_731feats_0.1...  4096x2048   \n",
       "155  2.742760  fm&p_1cycle_flgs_8192neurons_731feats_0.45drop...       8192   \n",
       "\n",
       "    features dropout cycle_len lrr  \n",
       "0        100    0.45        20  10  \n",
       "1        100    0.15        10  10  \n",
       "2        100    0.45        10  10  \n",
       "3        100     0.3        10  10  \n",
       "4        100    0.15        10  10  \n",
       "5        100    0.15        20  10  \n",
       "6        250     0.3        10  10  \n",
       "7        100    0.01        20  10  \n",
       "8        100     0.3        20  10  \n",
       "9        100     0.3        20  10  \n",
       "10       100    0.15        20  10  \n",
       "11       100    0.01        20  10  \n",
       "12       100    0.45        10  10  \n",
       "13       100    0.01        10  10  \n",
       "14       100     0.3        20  10  \n",
       "15       100     0.3        10  10  \n",
       "16       100    0.15        20  10  \n",
       "17       100    0.01        20  10  \n",
       "18       100     0.3        10  10  \n",
       "19       100    0.15        10  10  \n",
       "20       100    0.45        10  10  \n",
       "21       100    0.01        10  10  \n",
       "22       250    0.45        10  10  \n",
       "23       250     0.3        10  10  \n",
       "24       100    0.45        20  10  \n",
       "25       250    0.15        20  10  \n",
       "26       250     0.3        10  10  \n",
       "27       100    0.01        20  10  \n",
       "28       100    0.15        20  10  \n",
       "29       100     0.3        20  10  \n",
       "..       ...     ...       ...  ..  \n",
       "126      731    0.15        10  10  \n",
       "127      500    0.15        10  10  \n",
       "128      500    0.15        20  10  \n",
       "129      500     0.3        20  10  \n",
       "130      250    0.01        20  10  \n",
       "131      731    0.45        20  10  \n",
       "132      731    0.45        10  10  \n",
       "133      500    0.01        20  10  \n",
       "134      731    0.15        10  10  \n",
       "135      731    0.01        10  10  \n",
       "136      731    0.15        10  10  \n",
       "137      731    0.01        20  10  \n",
       "138      500     0.3        20  10  \n",
       "139      500    0.01        20  10  \n",
       "140      500    0.01        10  10  \n",
       "141      731    0.01        20  10  \n",
       "142      500    0.01        20  10  \n",
       "143      500    0.45        10  10  \n",
       "144      500    0.15        10  10  \n",
       "145      731    0.01        10  10  \n",
       "146      731    0.45        10  10  \n",
       "147      731    0.15        10  10  \n",
       "148      250    0.15        10  10  \n",
       "149      731     0.3        10  10  \n",
       "150      731     0.3        10  10  \n",
       "151      500    0.15        10  10  \n",
       "152      731     0.3        10  10  \n",
       "153      731     0.3        20  10  \n",
       "154      731    0.15        20  10  \n",
       "155      731    0.45        10  10  \n",
       "\n",
       "[156 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search - Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing full grid search, make sure that updated dataset has polynomial user data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Upper- and Lower-bounds for LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Size: 0.4999994466902672\n"
     ]
    }
   ],
   "source": [
    "validation_pct = 0.5\n",
    "dep = 'totals.transactionRevenue'\n",
    "dt = 'visitStartTimeLOCAL'\n",
    "yl = np.log1p(y)\n",
    "y_range = (0, np.max(yl) * 1.2)\n",
    "val_idx = get_timeseries_val_idxs(df, val_type = 'pct', val_pct = validation_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set arch\n",
    "arch = [1024, 512]\n",
    "dropout = [0.01, 0.01]\n",
    "\n",
    "md = ColumnarModelData.from_data_frame(path = 'models', val_idxs = val_idx, df = df, y = yl.astype(np.float32),\n",
    "                                       cat_flds = cat_vars, bs = 128, test_df = df_test)\n",
    "\n",
    "m = md.get_learner(emb_szs = emb_szs, n_cont = len(df.columns) - len(cat_vars), emb_drop = 0.04,\n",
    "                   out_sz = 1, szs = arch, drops = dropout, y_range = y_range )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45de173c302844aeb47480eb8e3ccc78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      4.390782   4.140962  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m.sched.plot(n_skip = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set arch\n",
    "arch = [16384, 8192]\n",
    "dropout = [0.01, 0.01]\n",
    "\n",
    "md = ColumnarModelData.from_data_frame(path = 'models', val_idxs = val_idx, df = df, y = yl.astype(np.float32),\n",
    "                                       cat_flds = cat_vars, bs = 128, test_df = df_test)\n",
    "\n",
    "m = md.get_learner(emb_szs = emb_szs, n_cont = len(df.columns) - len(cat_vars), emb_drop = 0.04,\n",
    "                   out_sz = 1, szs = arch, drops = dropout, y_range = y_range )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16155ab3008043e3b0fca128f30a98e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      4.182459   4.140962  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m.sched.plot(n_skip = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be worth adding two options for:\n",
    " - LR RATIO (10 vs 20)\n",
    " - CYCLE LEN (10 vs 20)\n",
    "\n",
    "Also, choose one wd and maybe remove one dropout (0.01, 0.15, 0.3) to reduce dims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "archs = [\n",
    "    \n",
    "    # single layer\n",
    "    [2048], [4096], [8192], [16384], [32768],\n",
    "    \n",
    "    # two layer\n",
    "    [1024, 512], [2048, 1024], [4096, 2048], [8192, 4096], [16384, 8192]\n",
    "    \n",
    "]\n",
    "\n",
    "lr_ratios = [10, 20]\n",
    "cycle_lens = [10, 20]\n",
    "\n",
    "dropouts = [0.01, 0.15, 0.30, 0.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arch_grid_search_iter(arch, dropout, wd):\n",
    "        \n",
    "        # print progress\n",
    "        model_name = 'full_features_1cycle_archgs_{}layers_{}neurons_{}dropout_{}wd_{}'.format(len(arch), 'x'.join(str(_) for _ in arch), dropout, wd, dt_str)\n",
    "        \n",
    "        # check if model has already been evaluated\n",
    "        if model_name[:-20] not in already_done:\n",
    "            \n",
    "            print('\\n\\nStarting:', model_name, '\\n')\n",
    "        \n",
    "            # init model objects\n",
    "            md = ColumnarModelData.from_data_frame(path = 'models', val_idxs = val_idx, df = df, y = yl.astype(np.float32),\n",
    "                                                   cat_flds = cat_vars, bs = 128, test_df = df_test)\n",
    "\n",
    "            m = md.get_learner(emb_szs = emb_szs, n_cont = len(df.columns) - len(cat_vars),\n",
    "                               emb_drop = 0.04, out_sz = 1, szs = arch, drops = [dropout for _ in arch], y_range = y_range)\n",
    "\n",
    "            # fit model\n",
    "            m.fit(lrs = 1e-4, n_cycle = 1, cycle_len = 14,\n",
    "                  wds = 1e-4, use_wd_sched = True, use_clr_beta = (10, 10, 0.95, 0.85),\n",
    "                  metrics = [rmse], best_save_name = model_name)\n",
    "\n",
    "            del md, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_done = [\n",
    "    'full_features_1cycle_archgs_1layers_32768neurons_0.01dropout_0.001wd',\n",
    "    'full_features_1cycle_archgs_1layers_16384neurons_0.01dropout_0.001wd',\n",
    "    'full_features_1cycle_archgs_1layers_8192neurons_0.01dropout_0.001wd',\n",
    "    'full_features_1cycle_archgs_1layers_4096neurons_0.01dropout_0.001wd',\n",
    "    'full_features_1cycle_archgs_1layers_2048neurons_0.01dropout_0.001wd'\n",
    "]\n",
    "\n",
    "for _wd in wds:\n",
    "    for _dropout in dropouts:\n",
    "        for _arch in archs:\n",
    "            arch_grid_search_iter(arch = _arch, dropout = _dropout, wd = _wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Grid Search Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_get_val_loss(saved_weights, loc_val_idx):\n",
    "    \n",
    "    # init model objects\n",
    "    md = ColumnarModelData.from_data_frame(path = 'models', val_idxs = loc_val_idx, df = df,\n",
    "                                          y = yl.astype(np.float32), cat_flds = cat_vars,\n",
    "                                          bs = 128, test_df = df_test)\n",
    "    \n",
    "    # set params\n",
    "    arch_str = saved_weights.split('_')[5].replace('neurons','')\n",
    "    if 'x' in arch_str:\n",
    "        arch = [int(x) for x in arch_str.split('x')]\n",
    "    else:\n",
    "        arch = [int(arch_str)]\n",
    "    dropout = [float(saved_weights.split('_')[6].replace('dropout','')) for _ in range(len(arch))]\n",
    "    \n",
    "    # init model\n",
    "    m = md.get_learner(emb_szs = emb_szs, n_cont = len(df.columns) - len(cat_vars),\n",
    "                       emb_drop = 0.04, out_sz = 1, szs = arch, drops = dropout, y_range = y_range)\n",
    "    \n",
    "    # load saved weights\n",
    "    m.load(saved_weights)\n",
    "    \n",
    "    # calc rmse\n",
    "    yl_val = deepcopy(yl[loc_val_idx])\n",
    "    yl_hat = deepcopy(m.predict().reshape(-1,))\n",
    "    loss = deepcopy(rmse(yl_hat, yl_val))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_loss = {}\n",
    "for w in saved_weights:\n",
    "    \n",
    "    print('starting:', w)\n",
    "    \n",
    "    # get validation idxs\n",
    "    val_idx_filename = 'validation_idxs_{}.pkl'.format(w.split('_')[-1])\n",
    "    with open(val_idx_filename, \"rb\") as input_file:\n",
    "        testing_val_idx = pickle.load(input_file)\n",
    "    \n",
    "    overall_loss[w] = load_model_get_val_loss(w, testing_val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    'full_features_1cycle_archgs_1layers_2048neurons_0.01dropout_0.001wd_2018-10-07-11-27-10': {\n",
    "        'val_calc_rmse': 2.2784808093892988,\n",
    "        'trn_min_loss': 2.564373,\n",
    "        'trn_min_rmse': 1.546203\n",
    "    },\n",
    "    'full_features_1cycle_archgs_1layers_4096neurons_0.01dropout_0.001wd_2018-10-07-11-27-10': {\n",
    "        'val_calc_rmse': 2.195621417020688,\n",
    "        'trn_min_loss': 2.548141,\n",
    "        'trn_min_rmse': 1.545662\n",
    "    },\n",
    "    'full_features_1cycle_archgs_2layers_1024x512neurons_0.01dropout_0.001wd_2018-10-07-20-39-50': {\n",
    "        'val_calc_rmse': 2.570256714661666,\n",
    "        'trn_min_loss': 2.518139,\n",
    "        'trn_min_rmse': 1.535893\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Grid-Search w/ `neg_rmse`\n",
    "\n",
    "(after digging into the `fastai` library, it was discovered that `best_save_name` saves the model with the *maximum* performance, which was originally intended to work with accuracy or a similar classification metric that you want to maximize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wd_grid_search_iter(wd, dropout, cycle_len = 25):\n",
    "\n",
    "    print('\\n\\nStarting:')\n",
    "    print('Weight Decay:', wd)\n",
    "    print('Dropout:', dropout[0])\n",
    "    if cycle_len == 25: print('Cycle Length:', cycle_len)\n",
    "    print()\n",
    "\n",
    "    # init model\n",
    "    md = ColumnarModelData.from_data_frame(path = 'models', val_idxs = val_idx, df = df, y = yl.astype(np.float32),\n",
    "                                           cat_flds = cat_vars, bs = 128, test_df = df_test)\n",
    "    m = md.get_learner(emb_szs = emb_szs, n_cont = len(df.columns) - len(cat_vars),\n",
    "                       emb_drop = 0.04, out_sz = 1, szs = arch, drops = dropout, y_range = y_range)\n",
    "\n",
    "    # fit model\n",
    "    m.fit(lrs = 1e-4, n_cycle = 1, cycle_len = cycle_len,\n",
    "          wds = wd, use_wd_sched = True, use_clr_beta = (10, 10, 0.95, 0.85),\n",
    "          metrics = [neg_rmse], best_save_name = 'full_features_1cycle_wdgs_wd{}_drop{}_{}'.format(wd, dropout[0], dt_str))\n",
    "\n",
    "    del md, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = [1024, 512]\n",
    "dropouts = [[0.01, 0.01], [0.1, 0.1], [0.2, 0.2]]\n",
    "wds = [1e-3, 1e-4, 1e-5, 1e-6, 0]\n",
    "\n",
    "for dropout in dropouts:\n",
    "    for wd in wds:\n",
    "        wd_grid_search_iter(wd = wd, dropout = dropout, cycle_len = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models & Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_get_val_loss(saved_weights, loc_val_idx):\n",
    "    \n",
    "    # get data object\n",
    "    md = ColumnarModelData.from_data_frame(path = 'models', val_idxs = loc_val_idx, df = df,\n",
    "                                           y = yl.astype(np.float32), cat_flds = cat_vars,\n",
    "                                           bs = 128, test_df = df_test)\n",
    "    \n",
    "    # init model\n",
    "    dropout = [float(saved_weights.split('_')[-2].replace('drop', '')) for _ in range(2)]\n",
    "    m = md.get_learner(emb_szs = emb_szs, n_cont = len(df.columns) - len(cat_vars),\n",
    "                       emb_drop = 0.04, out_sz = 1, szs = arch, drops = dropout, y_range = y_range)\n",
    "    \n",
    "    # load saved weights\n",
    "    m.load(saved_weights)\n",
    "    \n",
    "    # calc rmse\n",
    "    yl_val = deepcopy(yl[loc_val_idx])\n",
    "    yl_hat = deepcopy(m.predict().reshape(-1,))\n",
    "    loss = deepcopy(neg_rmse(yl_hat, yl_val))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting: full_features_1cycle_wdgs_wd0_drop0.01_2018-10-10-13-06-21\n",
      "starting: full_features_1cycle_wdgs_wd1e-06_drop0.01_2018-10-10-13-06-21\n",
      "starting: full_features_1cycle_wdgs_wd1e-05_drop0.01_2018-10-10-13-06-21\n",
      "starting: full_features_1cycle_wdgs_wd0.0001_drop0.01_2018-10-10-13-06-21\n",
      "starting: full_features_1cycle_wdgs_wd0.001_drop0.01_2018-10-10-13-06-21\n"
     ]
    }
   ],
   "source": [
    "saved_weights = [\n",
    "    'full_features_1cycle_wdgs_wd0_drop0.01_2018-10-10-13-06-21',\n",
    "    'full_features_1cycle_wdgs_wd1e-06_drop0.01_2018-10-10-13-06-21',\n",
    "    'full_features_1cycle_wdgs_wd1e-05_drop0.01_2018-10-10-13-06-21',\n",
    "    'full_features_1cycle_wdgs_wd0.0001_drop0.01_2018-10-10-13-06-21',\n",
    "    'full_features_1cycle_wdgs_wd0.001_drop0.01_2018-10-10-13-06-21'\n",
    "]\n",
    "\n",
    "val_idx_filename = 'validation_idxs_2018-10-10-13-06-21.pkl'\n",
    "\n",
    "with open(val_idx_filename, \"rb\") as input_file:\n",
    "    testing_val_idx = pickle.load(input_file)\n",
    "\n",
    "overall_loss = {}\n",
    "for w in saved_weights:\n",
    "    print('starting:', w)\n",
    "    overall_loss[w] = load_model_get_val_loss(w, testing_val_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Validation Predictions on Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d25a59bc5146799496aa93741226c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   neg_rmse   \n",
      "    0      2.609511   2.937018   -1.648727 \n",
      "    1      2.752639   2.67689    -1.582182 \n",
      "    2      2.72121    2.638024   -1.567019 \n",
      "    3      2.824484   2.616868   -1.564888 \n",
      "    4      2.47538    2.629752   -1.564153 \n",
      "    5      2.577455   2.627117   -1.569332 \n",
      "    6      2.241886   2.895021   -1.626933 \n",
      "    7      2.10251    2.721892   -1.58121  \n",
      "    8      2.109852   2.899992   -1.659028 \n",
      "    9      2.317027   2.68414    -1.589611 \n",
      "    10     1.886544   2.651551   -1.572613 \n",
      "    11     1.917104   2.645287   -1.561865 \n",
      "    12     1.897094   2.672715   -1.57557  \n",
      "    13     1.77871    2.663678   -1.569883 \n",
      "    14     1.755695   2.729286   -1.591549 \n",
      "    15     1.771692   2.69475    -1.575213 \n",
      "    16     1.375698   2.739276   -1.588298 \n",
      "    17     1.524395   2.762004   -1.597092 \n",
      "    18     1.238112   2.770292   -1.599913 \n",
      "    19     1.204172   2.772468   -1.599469 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.77247]), -1.5994691769563205]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params\n",
    "arch = [1024, 512]\n",
    "dropout = [0.01, 0.01]\n",
    "wd = 1e-3\n",
    "cycle_len = 20\n",
    "\n",
    "# init model\n",
    "md = ColumnarModelData.from_data_frame(\n",
    "    path = 'models',\n",
    "    val_idxs = val_idx,\n",
    "    df = df,\n",
    "    y = yl.astype(np.float32),\n",
    "    cat_flds = cat_vars,\n",
    "    bs = 128,\n",
    "    test_df = df_test\n",
    ")\n",
    "m = md.get_learner(\n",
    "    emb_szs = emb_szs,\n",
    "    n_cont = len(df.columns) - len(cat_vars),\n",
    "    emb_drop = 0.04,\n",
    "    out_sz = 1,\n",
    "    szs = arch,\n",
    "    drops = dropout,\n",
    "    y_range = y_range\n",
    ")\n",
    "\n",
    "# fit model\n",
    "m.fit(\n",
    "    lrs = 1e-4,\n",
    "    n_cycle = 1,\n",
    "    cycle_len = cycle_len,\n",
    "    wds = wd,\n",
    "    use_wd_sched = True,\n",
    "    use_clr_beta = (10, 10, 0.95, 0.85),\n",
    "    metrics = [neg_rmse],\n",
    "    best_save_name = 'full_features_1cycle_wdgs_wd{}_drop{}_{}'.format(wd, dropout[0], dt_str)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Other RMSE Calc Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "arch = [2056, 1024]\n",
    "dropout = [0.01, 0.01]\n",
    "wd = 1e-3\n",
    "cycle_len = 14\n",
    "\n",
    "# init model\n",
    "md = ColumnarModelData.from_data_frame(\n",
    "    path = 'models', val_idxs = val_idx, df = df, y = yl.astype(np.float32),\n",
    "    cat_flds = cat_vars, bs = 128, test_df = df_test\n",
    ")\n",
    "m = md.get_learner(\n",
    "    emb_szs = emb_szs, n_cont = len(df.columns) - len(cat_vars), emb_drop = 0.04,\n",
    "    out_sz = 1, szs = arch, drops = dropout, y_range = y_range\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f676541f0354e2ca8125d12d9e655c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   neg_rmse   \n",
      "    0      2.973824   3.040692   -1.701198 \n",
      "    1      2.743543   2.71746    -1.597625 \n",
      "    2      2.387177   2.63854    -1.578234 \n",
      "    3      2.178157   2.57083    -1.553115 \n",
      "    4      2.331694   2.56335    -1.539483 \n",
      "    5      2.575561   2.550403   -1.548109 \n",
      "    6      2.673461   2.597752   -1.569686 \n",
      "    7      2.132054   2.588603   -1.544525 \n",
      "    8      2.334287   2.600712   -1.565315 \n",
      "    9      2.314766   2.670822   -1.583428 \n",
      "    10     1.660972   2.586072   -1.547817 \n",
      "    11     1.736341   2.600977   -1.553405 \n",
      "    12     1.45087    2.611232   -1.554533 \n",
      "    13     1.701699   2.616454   -1.556258 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.61645]), -1.5562575230361118]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "m.fit(\n",
    "    lrs = 1e-4, n_cycle = 1, cycle_len = cycle_len, wds = wd, use_wd_sched = True, use_clr_beta = (20, 10, 0.95, 0.85),\n",
    "    metrics = [neg_rmse], best_save_name = 'full_features_1cycle_wdgs_wd{}_drop{}_{}'.format(wd, dropout[0], dt_str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_val_idx = deepcopy(pd.DataFrame(\n",
    "    {'val_idxs': val_idx}\n",
    ").sort_values('val_idxs').values.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6175457685263748"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc rmse\n",
    "yl_val = deepcopy(yl[sorted_val_idx])\n",
    "yl_hat = deepcopy(m.predict().reshape(-1,))\n",
    "abs(neg_rmse(yl_hat, yl_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_get_val_loss(saved_weights, loc_val_idx):\n",
    "    \n",
    "    # get data object\n",
    "    md = ColumnarModelData.from_data_frame(path = 'models', val_idxs = loc_val_idx, df = df,\n",
    "                                           y = yl.astype(np.float32), cat_flds = cat_vars,\n",
    "                                           bs = 128, test_df = df_test)\n",
    "    \n",
    "    # init model\n",
    "    dropout = [float(saved_weights.split('_')[-2].replace('drop', '')) for _ in range(2)]\n",
    "    m = md.get_learner(emb_szs = emb_szs, n_cont = len(df.columns) - len(cat_vars),\n",
    "                       emb_drop = 0.04, out_sz = 1, szs = arch, drops = dropout, y_range = y_range)\n",
    "    \n",
    "    # load saved weights\n",
    "    m.load(saved_weights)\n",
    "    \n",
    "    # calc rmse\n",
    "    yl_val = deepcopy(yl[loc_val_idx])\n",
    "    yl_hat = deepcopy(m.predict().reshape(-1,))\n",
    "    loss = deepcopy(neg_rmse(yl_hat, yl_val))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.6010464633142325"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model_get_val_loss('full_features_1cycle_wdgs_wd0.001_drop0.01_2018-10-11-13-08-53', sorted_val_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Notes\n",
    "\n",
    "Although I put a lot of work into this competition, I ultimately did not finish it due to the fact that some of the competitors were *kind of* \"cheating\" by scraping the Google Store Demo account for additional data that was previously redacted.\n",
    "\n",
    "While this was eventually brought to light by a few of the more honest competitors (or, suspicious after one user reduced the error of first place by 50% over night), it was only a few weeks before the end of the competition and Google (the competition owners) was forced to change the rules and essentially restart the competition. I had, by that time, moved on to other projects (and newer versions of the `fastai` library) and was too busy to refactor my model.\n",
    "\n",
    "It's unfortunate that I wasted so much time (*and GPU credits*) due to a competition oversight but it was still a really fun competition and a perfect way to explore how well the `fastai` library works with complex tabular data and how categorical embeddings can help neural nets beat highly-engineered RF/GBM/XGB.\n",
    "\n",
    "I hope you enjoyed it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
